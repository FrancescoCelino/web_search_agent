2025-06-11 17:22:11,743 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-11 17:22:11,744 - src.utils - INFO - Total documents loaded: 70
2025-06-11 17:22:11,748 - src.utils - INFO - Split documents into 148 chunks
2025-06-11 17:22:24,607 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-11 17:22:24,607 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-11 17:22:26,744 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-11 17:22:29,479 - src.tools - INFO - Vector store initialized successfully
2025-06-11 17:22:29,512 - src.tools - INFO - Database connection established
2025-06-11 17:22:29,512 - src.tools - INFO - All tools initialized successfully
2025-06-11 17:22:29,513 - src.tools - INFO - Available tools: 3
2025-06-11 17:22:29,522 - src.agent - INFO - AI Agent initialized successfully
2025-06-11 17:23:15,349 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 17:23:23,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 17:26:23,947 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 17:26:28,988 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 17:26:29,026 - src.tools - INFO - INSIDE RETRIEVER TOOL
2025-06-11 17:26:30,544 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 17:26:37,768 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 17:30:14,748 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 17:30:22,258 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:06:50,428 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:07:43,546 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:07:43,597 - src.tools - INFO - INSIDE RETRIEVER TOOL
2025-06-11 19:07:45,140 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:08:25,435 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:08:25,452 - src.tools - INFO - INSIDE RETRIEVER TOOL
2025-06-11 19:08:27,881 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:08:40,692 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:08:40,736 - src.tools - INFO - INSIDE RETRIEVER TOOL
2025-06-11 19:08:42,369 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:09:14,117 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:09:14,144 - src.tools - INFO - INSIDE RETRIEVER TOOL
2025-06-11 19:09:18,928 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:10:17,647 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:10:24,894 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-11 19:31:06,421 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:00:02,068 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 11:00:02,069 - src.utils - INFO - Total documents loaded: 70
2025-06-12 11:00:02,072 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 11:00:05,512 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 11:00:05,931 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 11:00:05,931 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 11:00:05,933 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 11:00:06,109 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 11:00:06,260 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 11:00:06,437 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 11:00:06,566 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 11:00:06,698 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 11:00:06,824 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 11:00:06,954 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 11:00:07,266 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 11:00:07,442 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 11:00:07,586 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 11:00:07,612 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 11:00:07,667 - chromadb.config - DEBUG - Starting component System
2025-06-12 11:00:07,667 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 11:00:08,200 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 11:00:08,599 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 11:00:10,347 - src.tools - INFO - Vector store initialized successfully
2025-06-12 11:00:10,366 - src.tools - INFO - Database connection established
2025-06-12 11:00:10,366 - src.tools - INFO - All tools initialized successfully
2025-06-12 11:00:10,400 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 11:03:11,327 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 11:03:11,328 - src.utils - INFO - Total documents loaded: 70
2025-06-12 11:03:11,330 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 11:03:14,682 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 11:03:15,142 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 11:03:15,142 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 11:03:15,144 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 11:03:15,361 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 11:03:15,496 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 11:03:15,633 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 11:03:15,829 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 11:03:15,964 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 11:03:16,110 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 11:03:16,246 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 11:03:16,572 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 11:03:16,756 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 11:03:16,913 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 11:03:16,948 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 11:03:16,982 - chromadb.config - DEBUG - Starting component System
2025-06-12 11:03:16,983 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 11:03:17,516 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 11:03:17,921 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 11:03:19,711 - src.tools - INFO - Vector store initialized successfully
2025-06-12 11:03:19,730 - src.tools - INFO - Database connection established
2025-06-12 11:03:19,730 - src.tools - INFO - All tools initialized successfully
2025-06-12 11:03:19,745 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 11:07:20,590 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443
2025-06-12 11:07:20,867 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "GET /info HTTP/1.1" 200 748
2025-06-12 11:07:20,875 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-c530b5f5-7f9e-401f-8878-e7fb7fff7243', 'json_data': {'messages': [{'content': '& C:/Users/celin/AppData/Local/Programs/Python/Python313/python.exe c:/Users/celin/Desktop/algoverde/web_search_agent/main.py', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 11:07:20,877 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:07:20,877 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 11:07:20,908 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000015916878EC0>
2025-06-12 11:07:20,908 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001596AFF5370> server_hostname='api.openai.com' timeout=None
2025-06-12 11:07:20,928 - langsmith.client - DEBUG - Sending multipart request with context: trace=858a6937-8fb2-468d-bd8a-4f3d348e359c,id=858a6937-8fb2-468d-bd8a-4f3d348e359c; trace=858a6937-8fb2-468d-bd8a-4f3d348e359c,id=9569f7de-170a-4085-abc0-0e94ecf80de0; trace=858a6937-8fb2-468d-bd8a-4f3d348e359c,id=fceb1d58-e821-4524-b4b9-d62bd0706bf1
2025-06-12 11:07:20,950 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001591695A850>
2025-06-12 11:07:20,950 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:07:20,951 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:07:20,951 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:07:20,952 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:07:20,952 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:07:21,088 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:07:23,182 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:07:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1981'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1984'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199966'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_fa0640604a21e7baa6af36733c7bc82e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cDD6.cXyIfGaFOZzDGDHN.K4ASAIhRYeZckmXTp0vb0-1749719242-1.0.1.1-p2uLoS2Vu1Ut0r5xu9zRUU4_Pv5EQkap4b4s1X4k7s9ns94voxhPchgJ4QToJYh9ZRQSkF3yxQpKe2W.FzPRWoi_HbYS.WMJOqKxY_e_pBs; path=/; expires=Thu, 12-Jun-25 09:37:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=tkUI9p5l1TAgbF54y6JYWOiLdTO7vOuAWAMCXEByFxg-1749719242438-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e832837f989468-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:07:23,186 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:07:23,187 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:07:23,189 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:07:23,191 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:07:23,192 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:07:23,195 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 12 Jun 2025 09:07:22 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'politecnico-di-torino-bgszq8'), ('openai-processing-ms', '1981'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '1984'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199966'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '10ms'), ('x-request-id', 'req_fa0640604a21e7baa6af36733c7bc82e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=cDD6.cXyIfGaFOZzDGDHN.K4ASAIhRYeZckmXTp0vb0-1749719242-1.0.1.1-p2uLoS2Vu1Ut0r5xu9zRUU4_Pv5EQkap4b4s1X4k7s9ns94voxhPchgJ4QToJYh9ZRQSkF3yxQpKe2W.FzPRWoi_HbYS.WMJOqKxY_e_pBs; path=/; expires=Thu, 12-Jun-25 09:37:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=tkUI9p5l1TAgbF54y6JYWOiLdTO7vOuAWAMCXEByFxg-1749719242438-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94e832837f989468-FCO'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-12 11:07:23,197 - openai._base_client - DEBUG - request_id: req_fa0640604a21e7baa6af36733c7bc82e
2025-06-12 11:07:23,233 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 11:07:23,749 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=858a6937-8fb2-468d-bd8a-4f3d348e359c,id=fceb1d58-e821-4524-b4b9-d62bd0706bf1; trace=858a6937-8fb2-468d-bd8a-4f3d348e359c,id=62887d36-c82f-4bea-9f4d-2454b8a08f33; trace=858a6937-8fb2-468d-bd8a-4f3d348e359c,id=62887d36-c82f-4bea-9f4d-2454b8a08f33; trace=858a6937-8fb2-468d-bd8a-4f3d348e359c,id=9569f7de-170a-4085-abc0-0e94ecf80de0; trace=858a6937-8fb2-468d-bd8a-4f3d348e359c,id=858a6937-8fb2-468d-bd8a-4f3d348e359c
2025-06-12 11:07:23,915 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:07:54,250 - langsmith.client - DEBUG - Main thread is dead, stopping compression thread
2025-06-12 11:07:54,251 - langsmith.client - DEBUG - Compressed traces control thread is shutting down
2025-06-12 11:07:54,350 - langsmith.client - DEBUG - Main thread is dead, stopping tracing thread
2025-06-12 11:07:54,350 - langsmith.client - DEBUG - Tracing control thread is shutting down
2025-06-12 11:07:54,352 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 11:07:54,860 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 11:08:08,043 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 11:08:08,043 - src.utils - INFO - Total documents loaded: 70
2025-06-12 11:08:08,046 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 11:08:11,452 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 11:08:11,868 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 11:08:11,869 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 11:08:11,871 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 11:08:12,048 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 11:08:12,232 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 11:08:12,363 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 11:08:12,493 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 11:08:12,620 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 11:08:12,755 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 11:08:12,882 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 11:08:13,208 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 11:08:13,379 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 11:08:13,536 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 11:08:13,561 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 11:08:13,593 - chromadb.config - DEBUG - Starting component System
2025-06-12 11:08:13,593 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 11:08:14,124 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 11:08:14,541 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 11:08:16,263 - src.tools - INFO - Vector store initialized successfully
2025-06-12 11:08:16,282 - src.tools - INFO - Database connection established
2025-06-12 11:08:16,283 - src.tools - INFO - All tools initialized successfully
2025-06-12 11:08:16,283 - src.tools - INFO - Web search tool created successfully
2025-06-12 11:08:16,283 - src.tools - INFO - Web search tool available
2025-06-12 11:08:16,283 - src.tools - INFO - Document retrieval tool available
2025-06-12 11:08:16,283 - src.tools - INFO - SQL tool available
2025-06-12 11:08:16,284 - src.tools - INFO - Total available tools: 3
2025-06-12 11:08:16,290 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 11:08:42,868 - src.agent - INFO - PROCESSING QUERY: 'search on the internet who is Riccardo Gioia (a software developer)'
2025-06-12 11:08:42,875 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443
2025-06-12 11:08:43,068 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "GET /info HTTP/1.1" 200 748
2025-06-12 11:08:43,134 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 11:08:43,138 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-8506fc0d-2b15-4db2-ad53-ec9f495d69c4', 'json_data': {'messages': [{'content': 'search on the internet who is Riccardo Gioia (a software developer)', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 11:08:43,138 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:08:43,139 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 11:08:43,193 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CF0751CAD0>
2025-06-12 11:08:43,194 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CF5BC8D1C0> server_hostname='api.openai.com' timeout=None
2025-06-12 11:08:43,252 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CF07569E50>
2025-06-12 11:08:43,252 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:08:43,253 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:08:43,254 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:08:43,255 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:08:43,256 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:08:43,695 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=018364d8-e08e-4d1d-b860-c403778da96c,id=018364d8-e08e-4d1d-b860-c403778da96c; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=15956a15-d8f7-414a-9d93-fbf6bf7ddb69; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=e4e124fb-9e1c-4c31-9fcc-70d7121a32c3
2025-06-12 11:08:43,862 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:08:44,968 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:08:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1127'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1131'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199981'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_4b0f0ae643e7befd5aeda8eece08f1bf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6HCpiLNY21Zo_fAbnFggjEF7Pa1ekB4J368NoI1pRCg-1749719324-1.0.1.1-uMVxXkxdbliqBc6k91abBR2OFwWSTlgoIJghdDCo3PJ98A2jwJPSWdp9ge7zYSC1nWWSjFcvz49K0RmR4ZdKdVuhjFe_yPTnlhcIq7E5MwU; path=/; expires=Thu, 12-Jun-25 09:38:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=a2GB3nbCbTXB51AOjgdVoSNFF7dDcZ92XEljVWpQPrY-1749719324221-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e83485dac2ea3f-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:08:44,975 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:08:44,977 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:08:44,980 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:08:44,982 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:08:44,983 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:08:44,985 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 12 Jun 2025 09:08:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'politecnico-di-torino-bgszq8'), ('openai-processing-ms', '1127'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '1131'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199981'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '5ms'), ('x-request-id', 'req_4b0f0ae643e7befd5aeda8eece08f1bf'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=6HCpiLNY21Zo_fAbnFggjEF7Pa1ekB4J368NoI1pRCg-1749719324-1.0.1.1-uMVxXkxdbliqBc6k91abBR2OFwWSTlgoIJghdDCo3PJ98A2jwJPSWdp9ge7zYSC1nWWSjFcvz49K0RmR4ZdKdVuhjFe_yPTnlhcIq7E5MwU; path=/; expires=Thu, 12-Jun-25 09:38:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=a2GB3nbCbTXB51AOjgdVoSNFF7dDcZ92XEljVWpQPrY-1749719324221-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94e83485dac2ea3f-FCO'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-12 11:08:44,988 - openai._base_client - DEBUG - request_id: req_4b0f0ae643e7befd5aeda8eece08f1bf
2025-06-12 11:08:45,004 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 11:08:45,009 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.tavily.com:443
2025-06-12 11:08:45,546 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=018364d8-e08e-4d1d-b860-c403778da96c,id=e4e124fb-9e1c-4c31-9fcc-70d7121a32c3; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=1f20e860-c765-4ef6-a632-99bcdb59b22b; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=1f20e860-c765-4ef6-a632-99bcdb59b22b; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=15956a15-d8f7-414a-9d93-fbf6bf7ddb69; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=53a8cb2c-d3d6-49bb-b734-d78e5609fffa; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=6c19e2c7-7e93-4316-9d0a-0c14b61b4116
2025-06-12 11:08:45,716 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:08:49,561 - urllib3.connectionpool - DEBUG - https://api.tavily.com:443 "POST /search HTTP/1.1" 200 766
2025-06-12 11:08:49,574 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 11:08:49,581 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ae3a8122-9f24-4033-a592-6dad05f87adf', 'json_data': {'messages': [{'content': 'search on the internet who is Riccardo Gioia (a software developer)', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_DbFpG6MMSb0zmWzv4smIIiB7', 'function': {'name': 'tavily_search_results_json', 'arguments': '{"query": "Riccardo Gioia software developer"}'}}]}, {'content': '[{"title": "Riccardo Gioia - Full-stack Developer - Tron Group Holding | LinkedIn", "url": "https://it.linkedin.com/in/riccardo-gioia-8b342a313", "content": "Software Engineer presso Tron Group Holding · Esperienza: Tron Group Holding · Formazione: Università degli studi di Parma · Località: Parma · 59", "score": 0.73914057}, {"title": "20+ \\"Riccardo Gioia\\" profiles - LinkedIn", "url": "https://www.linkedin.com/pub/dir/Riccardo/Gioia", "content": "Riccardo Gioia. Software Engineer presso Tron Group Holding. Parma. Tron Group Holding, +2 more. Università degli studi di Parma", "score": 0.70750624}]', 'role': 'tool', 'tool_call_id': 'call_DbFpG6MMSb0zmWzv4smIIiB7'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 11:08:49,586 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:08:49,587 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:08:49,589 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:08:49,591 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:08:49,593 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:08:49,593 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:08:50,132 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=018364d8-e08e-4d1d-b860-c403778da96c,id=6c19e2c7-7e93-4316-9d0a-0c14b61b4116; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=53a8cb2c-d3d6-49bb-b734-d78e5609fffa; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=adb6d25c-82ae-4861-a063-e559a20276e9; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=ef34629e-c05a-49f9-b215-6c611db24907
2025-06-12 11:08:50,305 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:08:51,303 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:08:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1462'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1474'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199826'), (b'x-ratelimit-reset-requests', b'11.29s'), (b'x-ratelimit-reset-tokens', b'52ms'), (b'x-request-id', b'req_9298f4227fc8ac782ce387bab03208be'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e834ad7ad3ea3f-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:08:51,306 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:08:51,307 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:08:51,310 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:08:51,311 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:08:51,312 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:08:51,313 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 09:08:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '1462', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1474', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199826', 'x-ratelimit-reset-requests': '11.29s', 'x-ratelimit-reset-tokens': '52ms', 'x-request-id': 'req_9298f4227fc8ac782ce387bab03208be', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e834ad7ad3ea3f-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 11:08:51,315 - openai._base_client - DEBUG - request_id: req_9298f4227fc8ac782ce387bab03208be
2025-06-12 11:08:51,321 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 11:08:51,333 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 11:08:51,334 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 11:08:51,336 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 11:08:51,338 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 11:08:51,340 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 11:08:51,342 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 11:08:51,344 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 11:08:51,346 - src.agent - INFO - FINAL RESPONSE: 446 characters
2025-06-12 11:08:51,884 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=018364d8-e08e-4d1d-b860-c403778da96c,id=ef34629e-c05a-49f9-b215-6c611db24907; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=780e8f8d-1be0-438d-8e95-21813848e117; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=780e8f8d-1be0-438d-8e95-21813848e117; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=adb6d25c-82ae-4861-a063-e559a20276e9; trace=018364d8-e08e-4d1d-b860-c403778da96c,id=018364d8-e08e-4d1d-b860-c403778da96c
2025-06-12 11:08:52,049 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:12:10,385 - src.agent - INFO - PROCESSING QUERY: 'thank you. What can you tell me about your internal database (you can use the SQL tool to explore it)'
2025-06-12 11:12:10,388 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 11:12:10,391 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-0afe8c0b-7ea9-416e-8ee0-cd74228ed13a', 'json_data': {'messages': [{'content': 'thank you. What can you tell me about your internal database (you can use the SQL tool to explore it)', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 11:12:10,393 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:12:10,393 - httpcore.connection - DEBUG - close.started
2025-06-12 11:12:10,394 - httpcore.connection - DEBUG - close.complete
2025-06-12 11:12:10,394 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 11:12:10,437 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CF0756A850>
2025-06-12 11:12:10,438 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CF5BC8D1C0> server_hostname='api.openai.com' timeout=None
2025-06-12 11:12:10,483 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CF075188A0>
2025-06-12 11:12:10,484 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:12:10,487 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:12:10,487 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:12:10,488 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:12:10,488 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:12:10,958 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=489887d0-e9a1-442b-84a5-333db1a9bae6; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=fe54f3a8-05d7-41d5-915c-a92d33b81e23
2025-06-12 11:12:11,132 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:12:11,576 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:12:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'588'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'593'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199972'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'8ms'), (b'x-request-id', b'req_56deb0ed2a588b89353a46eaa6c184b8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e839950a3f752d-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:12:11,577 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:12:11,577 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:12:11,579 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:12:11,579 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:12:11,579 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:12:11,580 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 09:12:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '588', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '593', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199972', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '8ms', 'x-request-id': 'req_56deb0ed2a588b89353a46eaa6c184b8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e839950a3f752d-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 11:12:11,580 - openai._base_client - DEBUG - request_id: req_56deb0ed2a588b89353a46eaa6c184b8
2025-06-12 11:12:11,586 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 11:12:11,589 - src.tools - INFO - SQL TOOL CALLED with question: Describe the contents and structure of the internal database.
2025-06-12 11:12:11,622 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a2dcc5d1-52c8-470d-a207-2ec99c09c64c', 'json_data': {'messages': [{'content': 'You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (") to denote them as delimited identifiers.\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\nPay attention to use date(\'now\') function to get the current date, if the question involves "today".\n\nUse the following format:\n\nQuestion: Question here\nSQLQuery: SQL Query to run\nSQLResult: Result of the SQLQuery\nAnswer: Final answer here\n\nOnly use the following tables:\n\nCREATE TABLE "Album" (\n\t"AlbumId" INTEGER NOT NULL, \n\t"Title" NVARCHAR(160) NOT NULL, \n\t"ArtistId" INTEGER NOT NULL, \n\tPRIMARY KEY ("AlbumId"), \n\tFOREIGN KEY("ArtistId") REFERENCES "Artist" ("ArtistId")\n)\n\n/*\n3 rows from Album table:\nAlbumId\tTitle\tArtistId\n1\tFor Those About To Rock We Salute You\t1\n2\tBalls to the Wall\t2\n3\tRestless and Wild\t2\n*/\n\n\nCREATE TABLE "Artist" (\n\t"ArtistId" INTEGER NOT NULL, \n\t"Name" NVARCHAR(120), \n\tPRIMARY KEY ("ArtistId")\n)\n\n/*\n3 rows from Artist table:\nArtistId\tName\n1\tAC/DC\n2\tAccept\n3\tAerosmith\n*/\n\n\nCREATE TABLE "Customer" (\n\t"CustomerId" INTEGER NOT NULL, \n\t"FirstName" NVARCHAR(40) NOT NULL, \n\t"LastName" NVARCHAR(20) NOT NULL, \n\t"Company" NVARCHAR(80), \n\t"Address" NVARCHAR(70), \n\t"City" NVARCHAR(40), \n\t"State" NVARCHAR(40), \n\t"Country" NVARCHAR(40), \n\t"PostalCode" NVARCHAR(10), \n\t"Phone" NVARCHAR(24), \n\t"Fax" NVARCHAR(24), \n\t"Email" NVARCHAR(60) NOT NULL, \n\t"SupportRepId" INTEGER, \n\tPRIMARY KEY ("CustomerId"), \n\tFOREIGN KEY("SupportRepId") REFERENCES "Employee" ("EmployeeId")\n)\n\n/*\n3 rows from Customer table:\nCustomerId\tFirstName\tLastName\tCompany\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\tSupportRepId\n1\tLuís\tGonçalves\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\tAv. Brigadeiro Faria Lima, 2170\tSão José dos Campos\tSP\tBrazil\t12227-000\t+55 (12) 3923-5555\t+55 (12) 3923-5566\tluisg@embraer.com.br\t3\n2\tLeonie\tKöhler\tNone\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t+49 0711 2842222\tNone\tleonekohler@surfeu.de\t5\n3\tFrançois\tTremblay\tNone\t1498 rue Bélanger\tMontréal\tQC\tCanada\tH2G 1A7\t+1 (514) 721-4711\tNone\tftremblay@gmail.com\t3\n*/\n\n\nCREATE TABLE "Employee" (\n\t"EmployeeId" INTEGER NOT NULL, \n\t"LastName" NVARCHAR(20) NOT NULL, \n\t"FirstName" NVARCHAR(20) NOT NULL, \n\t"Title" NVARCHAR(30), \n\t"ReportsTo" INTEGER, \n\t"BirthDate" DATETIME, \n\t"HireDate" DATETIME, \n\t"Address" NVARCHAR(70), \n\t"City" NVARCHAR(40), \n\t"State" NVARCHAR(40), \n\t"Country" NVARCHAR(40), \n\t"PostalCode" NVARCHAR(10), \n\t"Phone" NVARCHAR(24), \n\t"Fax" NVARCHAR(24), \n\t"Email" NVARCHAR(60), \n\tPRIMARY KEY ("EmployeeId"), \n\tFOREIGN KEY("ReportsTo") REFERENCES "Employee" ("EmployeeId")\n)\n\n/*\n3 rows from Employee table:\nEmployeeId\tLastName\tFirstName\tTitle\tReportsTo\tBirthDate\tHireDate\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\n1\tAdams\tAndrew\tGeneral Manager\tNone\t1962-02-18 00:00:00\t2002-08-14 00:00:00\t11120 Jasper Ave NW\tEdmonton\tAB\tCanada\tT5K 2N1\t+1 (780) 428-9482\t+1 (780) 428-3457\tandrew@chinookcorp.com\n2\tEdwards\tNancy\tSales Manager\t1\t1958-12-08 00:00:00\t2002-05-01 00:00:00\t825 8 Ave SW\tCalgary\tAB\tCanada\tT2P 2T3\t+1 (403) 262-3443\t+1 (403) 262-3322\tnancy@chinookcorp.com\n3\tPeacock\tJane\tSales Support Agent\t2\t1973-08-29 00:00:00\t2002-04-01 00:00:00\t1111 6 Ave SW\tCalgary\tAB\tCanada\tT2P 5M5\t+1 (403) 262-3443\t+1 (403) 262-6712\tjane@chinookcorp.com\n*/\n\n\nCREATE TABLE "Genre" (\n\t"GenreId" INTEGER NOT NULL, \n\t"Name" NVARCHAR(120), \n\tPRIMARY KEY ("GenreId")\n)\n\n/*\n3 rows from Genre table:\nGenreId\tName\n1\tRock\n2\tJazz\n3\tMetal\n*/\n\n\nCREATE TABLE "Invoice" (\n\t"InvoiceId" INTEGER NOT NULL, \n\t"CustomerId" INTEGER NOT NULL, \n\t"InvoiceDate" DATETIME NOT NULL, \n\t"BillingAddress" NVARCHAR(70), \n\t"BillingCity" NVARCHAR(40), \n\t"BillingState" NVARCHAR(40), \n\t"BillingCountry" NVARCHAR(40), \n\t"BillingPostalCode" NVARCHAR(10), \n\t"Total" NUMERIC(10, 2) NOT NULL, \n\tPRIMARY KEY ("InvoiceId"), \n\tFOREIGN KEY("CustomerId") REFERENCES "Customer" ("CustomerId")\n)\n\n/*\n3 rows from Invoice table:\nInvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n*/\n\n\nCREATE TABLE "InvoiceLine" (\n\t"InvoiceLineId" INTEGER NOT NULL, \n\t"InvoiceId" INTEGER NOT NULL, \n\t"TrackId" INTEGER NOT NULL, \n\t"UnitPrice" NUMERIC(10, 2) NOT NULL, \n\t"Quantity" INTEGER NOT NULL, \n\tPRIMARY KEY ("InvoiceLineId"), \n\tFOREIGN KEY("TrackId") REFERENCES "Track" ("TrackId"), \n\tFOREIGN KEY("InvoiceId") REFERENCES "Invoice" ("InvoiceId")\n)\n\n/*\n3 rows from InvoiceLine table:\nInvoiceLineId\tInvoiceId\tTrackId\tUnitPrice\tQuantity\n1\t1\t2\t0.99\t1\n2\t1\t4\t0.99\t1\n3\t2\t6\t0.99\t1\n*/\n\n\nCREATE TABLE "MediaType" (\n\t"MediaTypeId" INTEGER NOT NULL, \n\t"Name" NVARCHAR(120), \n\tPRIMARY KEY ("MediaTypeId")\n)\n\n/*\n3 rows from MediaType table:\nMediaTypeId\tName\n1\tMPEG audio file\n2\tProtected AAC audio file\n3\tProtected MPEG-4 video file\n*/\n\n\nCREATE TABLE "Playlist" (\n\t"PlaylistId" INTEGER NOT NULL, \n\t"Name" NVARCHAR(120), \n\tPRIMARY KEY ("PlaylistId")\n)\n\n/*\n3 rows from Playlist table:\nPlaylistId\tName\n1\tMusic\n2\tMovies\n3\tTV Shows\n*/\n\n\nCREATE TABLE "PlaylistTrack" (\n\t"PlaylistId" INTEGER NOT NULL, \n\t"TrackId" INTEGER NOT NULL, \n\tPRIMARY KEY ("PlaylistId", "TrackId"), \n\tFOREIGN KEY("TrackId") REFERENCES "Track" ("TrackId"), \n\tFOREIGN KEY("PlaylistId") REFERENCES "Playlist" ("PlaylistId")\n)\n\n/*\n3 rows from PlaylistTrack table:\nPlaylistId\tTrackId\n1\t3402\n1\t3389\n1\t3390\n*/\n\n\nCREATE TABLE "Track" (\n\t"TrackId" INTEGER NOT NULL, \n\t"Name" NVARCHAR(200) NOT NULL, \n\t"AlbumId" INTEGER, \n\t"MediaTypeId" INTEGER NOT NULL, \n\t"GenreId" INTEGER, \n\t"Composer" NVARCHAR(220), \n\t"Milliseconds" INTEGER NOT NULL, \n\t"Bytes" INTEGER, \n\t"UnitPrice" NUMERIC(10, 2) NOT NULL, \n\tPRIMARY KEY ("TrackId"), \n\tFOREIGN KEY("MediaTypeId") REFERENCES "MediaType" ("MediaTypeId"), \n\tFOREIGN KEY("GenreId") REFERENCES "Genre" ("GenreId"), \n\tFOREIGN KEY("AlbumId") REFERENCES "Album" ("AlbumId")\n)\n\n/*\n3 rows from Track table:\nTrackId\tName\tAlbumId\tMediaTypeId\tGenreId\tComposer\tMilliseconds\tBytes\tUnitPrice\n1\tFor Those About To Rock (We Salute You)\t1\t1\t1\tAngus Young, Malcolm Young, Brian Johnson\t343719\t11170334\t0.99\n2\tBalls to the Wall\t2\t2\t1\tNone\t342562\t5510424\t0.99\n3\tFast As a Shark\t3\t2\t1\tF. Baltes, S. Kaufman, U. Dirkscneider & W. Hoffman\t230619\t3990994\t0.99\n*/\n\nQuestion: Describe the contents and structure of the internal database.\nSQLQuery: ', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stop': ['\nSQLResult:'], 'stream': False}}
2025-06-12 11:12:11,623 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:12:11,623 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:12:11,624 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:12:11,624 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:12:11,624 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:12:11,624 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:12:12,194 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=fe54f3a8-05d7-41d5-915c-a92d33b81e23; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=0e9aa183-9471-4a72-9d3c-0a2d5cca415f; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=0e9aa183-9471-4a72-9d3c-0a2d5cca415f; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=489887d0-e9a1-442b-84a5-333db1a9bae6; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=c23a3dec-40b9-4970-8dd1-6dc025e6a3d5; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=786af897-a953-4a9a-a35b-811898d78003; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=b0ea322a-68e0-4796-97dc-6c6ed09d7e4b; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=87a8a29c-95dc-492e-9221-b17177e2e910; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=9e3c02c3-6ea0-4d8f-9c33-70989bb15ce6; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=af4ad8cb-ad56-4301-87b9-2bf510ab780a; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f7e0d5b3-31e5-42a3-b033-6f4817e226cd; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=8971ea41-5c4e-4a0f-92fc-cb09722acf26; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=172409d1-9625-4bf1-b18d-fe9be688a719; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=172409d1-9625-4bf1-b18d-fe9be688a719; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=b872f96c-12de-462a-aebb-d3be7c568437; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=b872f96c-12de-462a-aebb-d3be7c568437; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=8971ea41-5c4e-4a0f-92fc-cb09722acf26; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f7e0d5b3-31e5-42a3-b033-6f4817e226cd; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=1ae9a51d-c97d-4751-871a-936d9fae90ac; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=1ae9a51d-c97d-4751-871a-936d9fae90ac; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=8537a234-e2ae-433a-80fd-d499335c08d9; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=8537a234-e2ae-433a-80fd-d499335c08d9; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f84dd9ee-7805-4340-979a-fef6350409fd
2025-06-12 11:12:12,402 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:12:12,675 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:12:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'765'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'769'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'198233'), (b'x-ratelimit-reset-requests', b'16.34s'), (b'x-ratelimit-reset-tokens', b'529ms'), (b'x-request-id', b'req_d50e5f559965d33bc01365efc152699d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8399c2e2c752d-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:12:12,676 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:12:12,677 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:12:12,682 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:12:12,682 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:12:12,682 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:12:12,683 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 09:12:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '765', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '769', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '198233', 'x-ratelimit-reset-requests': '16.34s', 'x-ratelimit-reset-tokens': '529ms', 'x-request-id': 'req_d50e5f559965d33bc01365efc152699d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8399c2e2c752d-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 11:12:12,684 - openai._base_client - DEBUG - request_id: req_d50e5f559965d33bc01365efc152699d
2025-06-12 11:12:12,704 - src.tools - INFO - SQL TOOL RESULT: 162 characters
2025-06-12 11:12:12,706 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 11:12:12,707 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-3ff787c5-3deb-4b05-a462-a083caf78084', 'json_data': {'messages': [{'content': 'thank you. What can you tell me about your internal database (you can use the SQL tool to explore it)', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_yHkTzpXalklLMt7Ip1d0G104', 'function': {'name': 'nl2sql_tool', 'arguments': '{"question": "Describe the contents and structure of the internal database."}'}}]}, {'content': "[('Album',), ('Artist',), ('Customer',), ('Employee',), ('Genre',), ('Invoice',), ('InvoiceLine',), ('MediaType',), ('Playlist',), ('PlaylistTrack',), ('Track',)]", 'role': 'tool', 'tool_call_id': 'call_yHkTzpXalklLMt7Ip1d0G104'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 11:12:12,708 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:12:12,708 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:12:12,709 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:12:12,709 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:12:12,709 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:12:12,710 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:12:13,268 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f84dd9ee-7805-4340-979a-fef6350409fd; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=3c4eee7f-6c7d-465f-a19a-6b6dc63812e6; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=3c4eee7f-6c7d-465f-a19a-6b6dc63812e6; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=1d6ce00e-866c-4ef2-abb9-6f6b0fce32e6; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=1d6ce00e-866c-4ef2-abb9-6f6b0fce32e6; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=c6df6b83-ec2b-4c61-ab2d-e5195993c27b; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=c6df6b83-ec2b-4c61-ab2d-e5195993c27b; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=af4ad8cb-ad56-4301-87b9-2bf510ab780a; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=9e3c02c3-6ea0-4d8f-9c33-70989bb15ce6; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=87a8a29c-95dc-492e-9221-b17177e2e910; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f0cc4784-c699-4ca4-b707-c67a4fec4370; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=63a31f42-0ec3-4bb8-9543-39b103f6db1a; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f4543106-06fe-4eb5-a77d-fe34edb98d44; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=011776c0-7df1-4f6b-a62e-0b740bfd0daf; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=011776c0-7df1-4f6b-a62e-0b740bfd0daf; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=2f231a5f-b025-415d-a2f9-0ec87dc68f3b; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=2f231a5f-b025-415d-a2f9-0ec87dc68f3b; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f4543106-06fe-4eb5-a77d-fe34edb98d44; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=63a31f42-0ec3-4bb8-9543-39b103f6db1a; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f0cc4784-c699-4ca4-b707-c67a4fec4370; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=b0ea322a-68e0-4796-97dc-6c6ed09d7e4b; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=786af897-a953-4a9a-a35b-811898d78003; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=c23a3dec-40b9-4970-8dd1-6dc025e6a3d5; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=ecbbaac8-4f62-4cca-bb0a-8c654c073781; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=855800e8-fba4-4e32-b7a6-658711c807c1
2025-06-12 11:12:13,485 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:12:15,467 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:12:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'2544'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2548'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199930'), (b'x-ratelimit-reset-requests', b'23.967s'), (b'x-ratelimit-reset-tokens', b'21ms'), (b'x-request-id', b'req_887daf4e0a9cc58b94f4e3d4c31519c9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e839a2e877752d-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:12:15,470 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:12:15,472 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:12:15,474 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:12:15,475 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:12:15,476 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:12:15,477 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 09:12:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '2544', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2548', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '199930', 'x-ratelimit-reset-requests': '23.967s', 'x-ratelimit-reset-tokens': '21ms', 'x-request-id': 'req_887daf4e0a9cc58b94f4e3d4c31519c9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e839a2e877752d-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 11:12:15,482 - openai._base_client - DEBUG - request_id: req_887daf4e0a9cc58b94f4e3d4c31519c9
2025-06-12 11:12:15,487 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 11:12:15,492 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 11:12:15,493 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 11:12:15,493 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 11:12:15,494 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 11:12:15,494 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 11:12:15,494 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 11:12:15,495 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 11:12:15,497 - src.agent - INFO - FINAL RESPONSE: 785 characters
2025-06-12 11:12:16,053 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=855800e8-fba4-4e32-b7a6-658711c807c1; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=9447e806-f6e2-4d5e-9923-c8a68bcdf321; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=9447e806-f6e2-4d5e-9923-c8a68bcdf321; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=ecbbaac8-4f62-4cca-bb0a-8c654c073781; trace=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b,id=f5b814dc-7a0e-42f1-8b42-f0bb8169a34b
2025-06-12 11:12:16,219 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:14:51,468 - src.agent - INFO - PROCESSING QUERY: 'yeah, about the software engineer I asked you before about, what was his name again?'
2025-06-12 11:14:51,471 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 11:14:51,474 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a715af4c-634b-4b2b-8e4b-d55462da48a3', 'json_data': {'messages': [{'content': 'yeah, about the software engineer I asked you before about, what was his name again?', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 11:14:51,476 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:14:51,476 - httpcore.connection - DEBUG - close.started
2025-06-12 11:14:51,477 - httpcore.connection - DEBUG - close.complete
2025-06-12 11:14:51,477 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 11:14:51,526 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CF0751B950>
2025-06-12 11:14:51,527 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CF5BC8D1C0> server_hostname='api.openai.com' timeout=None
2025-06-12 11:14:51,578 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CF074AEC30>
2025-06-12 11:14:51,578 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:14:51,579 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:14:51,579 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:14:51,580 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:14:51,580 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:14:52,038 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=e3e26853-037b-4312-8485-eef739794b79,id=e3e26853-037b-4312-8485-eef739794b79; trace=e3e26853-037b-4312-8485-eef739794b79,id=d8ab80be-0e03-40b0-9663-b301e2b1a6a0; trace=e3e26853-037b-4312-8485-eef739794b79,id=fc14aaf5-c1f1-4b98-8787-e8da9f338fb5
2025-06-12 11:14:52,210 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:14:52,539 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:14:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'555'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'558'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199976'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_ddbf086d465795f1edf18f32315c3959'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e83d83dc5a77fa-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:14:52,540 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:14:52,541 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:14:52,541 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:14:52,541 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:14:52,542 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:14:52,542 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 09:14:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '555', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '558', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199976', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6ms', 'x-request-id': 'req_ddbf086d465795f1edf18f32315c3959', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e83d83dc5a77fa-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 11:14:52,542 - openai._base_client - DEBUG - request_id: req_ddbf086d465795f1edf18f32315c3959
2025-06-12 11:14:52,557 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 11:14:52,566 - src.tools - INFO - DOCUMENT RETRIEVAL TOOL CALLED with question: What was the name of the software engineer mentioned previously?
2025-06-12 11:14:52,768 - src.tools - INFO - DOCUMENT RETRIEVAL RESULT: 1844 characters, 2 documents
2025-06-12 11:14:52,788 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 11:14:52,791 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-b4824753-5981-4ca5-84fd-ae82fa3cfa34', 'json_data': {'messages': [{'content': 'yeah, about the software engineer I asked you before about, what was his name again?', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_SWHx8AkQHOyMABS3RRXZ3glI', 'function': {'name': 'retriever_tool', 'arguments': '{"question": "What was the name of the software engineer mentioned previously?"}'}}]}, {'content': 'Chapter 3\nCoding and Implementation\nNext, we will describe the practical aspects of implementing our SEINR model using\nPython. The implementation relies on a combination of high-level libraries for numerical\ncomputations, data handling, and file management. We will also describe the strategy\nwe employed to numerically solve a time-discrete system of ODEs.\nFrom now on, the non-bayesian strategy of using a fixed distribution of parameters\neach week (without a posteriori updates) will be considered a particular case of bayesian\nmodelling where the prior distribution is equal to the posterior: this is done to avoid\nconfusion and for brevitys sake, since most sections of the code are similar for both\nstrategies.\n3.1 Coding Bayesian Inference\nOur approach to Bayesian inference relies on a combination of Python libraries.NumPy is\nused for computationally efficient math operations and array management. For example,\n\nChapter 3\nCoding and Implementation\nNext, we will describe the practical aspects of implementing our SEINR model using\nPython. The implementation relies on a combination of high-level libraries for numerical\ncomputations, data handling, and file management. We will also describe the strategy\nwe employed to numerically solve a time-discrete system of ODEs.\nFrom now on, the non-bayesian strategy of using a fixed distribution of parameters\neach week (without a posteriori updates) will be considered a particular case of bayesian\nmodelling where the prior distribution is equal to the posterior: this is done to avoid\nconfusion and for brevitys sake, since most sections of the code are similar for both\nstrategies.\n3.1 Coding Bayesian Inference\nOur approach to Bayesian inference relies on a combination of Python libraries.NumPy is\nused for computationally efficient math operations and array management. For example,', 'role': 'tool', 'tool_call_id': 'call_SWHx8AkQHOyMABS3RRXZ3glI'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 11:14:52,792 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:14:52,792 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:14:52,792 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:14:52,793 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:14:52,794 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:14:52,794 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:14:52,963 - urllib3.connectionpool - DEBUG - Resetting dropped connection: us.i.posthog.com
2025-06-12 11:14:53,303 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=e3e26853-037b-4312-8485-eef739794b79,id=fc14aaf5-c1f1-4b98-8787-e8da9f338fb5; trace=e3e26853-037b-4312-8485-eef739794b79,id=c3994a5a-1f1d-466d-8b31-fb195d4610ab; trace=e3e26853-037b-4312-8485-eef739794b79,id=c3994a5a-1f1d-466d-8b31-fb195d4610ab; trace=e3e26853-037b-4312-8485-eef739794b79,id=d8ab80be-0e03-40b0-9663-b301e2b1a6a0; trace=e3e26853-037b-4312-8485-eef739794b79,id=702f78e1-532e-4be7-ac58-798ff84bd274; trace=e3e26853-037b-4312-8485-eef739794b79,id=e50a0eee-de94-488d-be7f-2243dee0e1b2; trace=e3e26853-037b-4312-8485-eef739794b79,id=4bba45b0-b819-42a3-b807-74f105bc776f; trace=e3e26853-037b-4312-8485-eef739794b79,id=4bba45b0-b819-42a3-b807-74f105bc776f; trace=e3e26853-037b-4312-8485-eef739794b79,id=e50a0eee-de94-488d-be7f-2243dee0e1b2; trace=e3e26853-037b-4312-8485-eef739794b79,id=702f78e1-532e-4be7-ac58-798ff84bd274; trace=e3e26853-037b-4312-8485-eef739794b79,id=b0ec339c-efbb-4075-b9c4-697b340a72bf; trace=e3e26853-037b-4312-8485-eef739794b79,id=94fd8139-dab7-4400-b49b-46269123172f
2025-06-12 11:14:53,356 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 11:14:53,485 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:14:53,942 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:14:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'939'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'941'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199512'), (b'x-ratelimit-reset-requests', b'16.253s'), (b'x-ratelimit-reset-tokens', b'146ms'), (b'x-request-id', b'req_fce1adc2f791f1077bb1e171072f12c1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e83d8b6e4b77fa-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:14:53,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:14:53,945 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:14:54,015 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:14:54,016 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:14:54,017 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:14:54,018 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 09:14:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '939', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '941', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199512', 'x-ratelimit-reset-requests': '16.253s', 'x-ratelimit-reset-tokens': '146ms', 'x-request-id': 'req_fce1adc2f791f1077bb1e171072f12c1', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e83d8b6e4b77fa-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 11:14:54,020 - openai._base_client - DEBUG - request_id: req_fce1adc2f791f1077bb1e171072f12c1
2025-06-12 11:14:54,035 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 11:14:54,042 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 11:14:54,043 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 11:14:54,043 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 11:14:54,044 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 11:14:54,044 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 11:14:54,045 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 11:14:54,045 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 11:14:54,045 - src.agent - INFO - FINAL RESPONSE: 227 characters
2025-06-12 11:14:54,595 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=e3e26853-037b-4312-8485-eef739794b79,id=94fd8139-dab7-4400-b49b-46269123172f; trace=e3e26853-037b-4312-8485-eef739794b79,id=56f349b2-1540-487d-884f-f01e9a96407e; trace=e3e26853-037b-4312-8485-eef739794b79,id=56f349b2-1540-487d-884f-f01e9a96407e; trace=e3e26853-037b-4312-8485-eef739794b79,id=b0ec339c-efbb-4075-b9c4-697b340a72bf; trace=e3e26853-037b-4312-8485-eef739794b79,id=e3e26853-037b-4312-8485-eef739794b79
2025-06-12 11:14:54,752 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:16:56,713 - src.agent - INFO - PROCESSING QUERY: 'it was earlier in the conversation'
2025-06-12 11:16:56,715 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 11:16:56,718 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d5c167f5-cefc-403a-9888-7f2f6cd3040f', 'json_data': {'messages': [{'content': 'it was earlier in the conversation', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 11:16:56,719 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 11:16:56,720 - httpcore.connection - DEBUG - close.started
2025-06-12 11:16:56,720 - httpcore.connection - DEBUG - close.complete
2025-06-12 11:16:56,721 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 11:16:56,756 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CF07587DF0>
2025-06-12 11:16:56,756 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CF5BC8D1C0> server_hostname='api.openai.com' timeout=None
2025-06-12 11:16:56,805 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CF07587F00>
2025-06-12 11:16:56,807 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 11:16:56,809 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 11:16:56,810 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 11:16:56,811 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 11:16:56,812 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 11:16:57,235 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4,id=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4; trace=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4,id=8601b4e1-9e37-47ce-b087-7168d53b0b0f; trace=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4,id=c22c554e-2a39-4f05-b2b5-042e8307f175
2025-06-12 11:16:57,400 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 11:16:57,464 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 09:16:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'424'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199988'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_99272276037425f5d43ec139e84779f0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e840928a05ea63-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 11:16:57,465 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 11:16:57,466 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 11:16:57,466 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 11:16:57,466 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 11:16:57,466 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 11:16:57,467 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 09:16:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '421', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '424', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199988', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_99272276037425f5d43ec139e84779f0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e840928a05ea63-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 11:16:57,467 - openai._base_client - DEBUG - request_id: req_99272276037425f5d43ec139e84779f0
2025-06-12 11:16:57,482 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 11:16:57,484 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 11:16:57,484 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 11:16:57,484 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 11:16:57,484 - src.agent - INFO - FINAL RESPONSE: 101 characters
2025-06-12 11:16:58,021 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4,id=c22c554e-2a39-4f05-b2b5-042e8307f175; trace=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4,id=69a9bee7-51d5-4874-894a-84db976886d1; trace=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4,id=69a9bee7-51d5-4874-894a-84db976886d1; trace=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4,id=8601b4e1-9e37-47ce-b087-7168d53b0b0f; trace=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4,id=bd2ecc7a-e773-4c4e-ad59-4026e6afb7f4
2025-06-12 11:16:58,183 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:15:35,174 - langsmith.client - DEBUG - Main thread is dead, stopping compression thread
2025-06-12 12:15:35,177 - langsmith.client - DEBUG - Compressed traces control thread is shutting down
2025-06-12 12:15:35,223 - langsmith.client - DEBUG - Main thread is dead, stopping tracing thread
2025-06-12 12:15:35,225 - langsmith.client - DEBUG - Tracing control thread is shutting down
2025-06-12 12:15:35,231 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 12:15:35,277 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 12:15:45,917 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 12:15:45,917 - src.utils - INFO - Total documents loaded: 70
2025-06-12 12:15:45,920 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 12:15:49,397 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 12:15:49,876 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 12:15:49,876 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 12:15:49,878 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 12:15:50,075 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 12:15:50,212 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 12:15:50,345 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 12:15:50,512 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 12:15:50,646 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 12:15:50,787 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 12:15:50,922 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 12:15:51,215 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 12:15:51,377 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 12:15:51,534 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 12:15:51,560 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 12:15:51,592 - chromadb.config - DEBUG - Starting component System
2025-06-12 12:15:51,592 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 12:15:52,123 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 12:15:52,546 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 12:15:54,251 - src.tools - INFO - Vector store initialized successfully
2025-06-12 12:15:54,272 - src.tools - INFO - Database connection established
2025-06-12 12:15:54,272 - src.tools - INFO - All tools initialized successfully
2025-06-12 12:15:54,272 - src.tools - INFO - Web search tool created successfully
2025-06-12 12:15:54,272 - src.tools - INFO - Web search tool available
2025-06-12 12:15:54,273 - src.tools - INFO - Document retrieval tool available
2025-06-12 12:15:54,273 - src.tools - INFO - SQL tool available
2025-06-12 12:15:54,273 - src.tools - INFO - Total available tools: 3
2025-06-12 12:15:54,280 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 12:16:19,571 - src.agent - INFO - PROCESSING QUERY: 'search on the internet if you can find any info about Riccardo Gioia, a software engineer'
2025-06-12 12:16:19,580 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443
2025-06-12 12:16:19,765 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 12:16:19,769 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-5b2d3530-23d2-426b-b002-f92f96c061fe', 'json_data': {'messages': [{'content': 'search on the internet if you can find any info about Riccardo Gioia, a software engineer', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 12:16:19,769 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 12:16:19,770 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 12:16:19,799 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B930F08EC0>
2025-06-12 12:16:19,799 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B9056292E0> server_hostname='api.openai.com' timeout=None
2025-06-12 12:16:19,800 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "GET /info HTTP/1.1" 200 748
2025-06-12 12:16:19,844 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B930F6DD10>
2025-06-12 12:16:19,844 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 12:16:19,845 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 12:16:19,845 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 12:16:19,846 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 12:16:19,846 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 12:16:19,859 - langsmith.client - DEBUG - Sending multipart request with context: trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=d10503d0-3809-4924-9b19-e0bca23a5512; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=511397c7-f490-4b91-9298-62b693863aab; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=5360d0ac-f8b3-4b03-b180-a1968d54dd1b
2025-06-12 12:16:20,023 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:16:20,976 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 10:16:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'640'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'647'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199975'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_b53abe7db5a124931232b0eb286e55b2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ohZb3bzrYYlQyKqwgBRzpGhGBn6IqT8pfYLIoH.VS0w-1749723380-1.0.1.1-mT0mUAXLpXEmOxLqQeTKh8xqbwGfmpOl.u26sq4RCH6aHH2Er39Ej_BZjpJ0SO4U9wYMRTmwVE9Hw8dtBMB3YgTU5Hzz6aIwWkH8kaqJ9_0; path=/; expires=Thu, 12-Jun-25 10:46:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=jcU_8kgZ6cz7_uNlHqfbcvQwKdwqaQOmffLidGMTxww-1749723380206-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8978f6a566130-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 12:16:20,981 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 12:16:20,982 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 12:16:20,985 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 12:16:20,986 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 12:16:20,987 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 12:16:20,988 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 12 Jun 2025 10:16:20 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'politecnico-di-torino-bgszq8'), ('openai-processing-ms', '640'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '647'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199975'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_b53abe7db5a124931232b0eb286e55b2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ohZb3bzrYYlQyKqwgBRzpGhGBn6IqT8pfYLIoH.VS0w-1749723380-1.0.1.1-mT0mUAXLpXEmOxLqQeTKh8xqbwGfmpOl.u26sq4RCH6aHH2Er39Ej_BZjpJ0SO4U9wYMRTmwVE9Hw8dtBMB3YgTU5Hzz6aIwWkH8kaqJ9_0; path=/; expires=Thu, 12-Jun-25 10:46:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=jcU_8kgZ6cz7_uNlHqfbcvQwKdwqaQOmffLidGMTxww-1749723380206-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94e8978f6a566130-FCO'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-12 12:16:20,990 - openai._base_client - DEBUG - request_id: req_b53abe7db5a124931232b0eb286e55b2
2025-06-12 12:16:21,001 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 12:16:21,006 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.tavily.com:443
2025-06-12 12:16:21,527 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=5360d0ac-f8b3-4b03-b180-a1968d54dd1b; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=f7cea614-a16c-4ae9-aedc-6851b7f3356d; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=f7cea614-a16c-4ae9-aedc-6851b7f3356d; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=511397c7-f490-4b91-9298-62b693863aab; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=18354a15-cdf0-420d-ae21-729964a51094; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=594dd005-fe7f-461d-b8cf-9e5308c933a2
2025-06-12 12:16:21,692 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:16:23,265 - urllib3.connectionpool - DEBUG - https://api.tavily.com:443 "POST /search HTTP/1.1" 200 1758
2025-06-12 12:16:23,277 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 12:16:23,289 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-1605c976-b09c-4650-b3a4-b1c488cd1a39', 'json_data': {'messages': [{'content': 'search on the internet if you can find any info about Riccardo Gioia, a software engineer', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_JBeAINBkTNsa18Tw2DWnrevk', 'function': {'name': 'tavily_search_results_json', 'arguments': '{"query": "Riccardo Gioia software engineer"}'}}]}, {'content': '[{"title": "Riccardo Gioia - Full-stack Developer - Tron Group Holding | LinkedIn", "url": "https://it.linkedin.com/in/riccardo-gioia-8b342a313", "content": "# Riccardo Gioia\\n**Software Engineer presso Tron Group Holding**  \\nParma, Italy  \\n60 connections, 60 followers\\n\\n## About\\nN/A [...] ## Education\\n### Università degli Studi di Parma  \\n Laurea in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n### Università degli Studi di Parma  \\n Laurea Magistrale in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n## Skills\\n**Front End Engineering Design (FEED)**, **Tecnologie Web**, **Settore software**, **Progettazione software**, **Java**, **Sviluppo Web**, **Sviluppo front-end**\\n\\n## Certifications\\nN/A\\n\\n## Volunteer Work\\nN/A\\n\\n## Languages\\nN/A\\n\\n## Groups\\nN/A [...] * [Marco Todaro](https://www.linkedin.com/in/marc0todar0) - Software Engineer presso Wide Group SpA.\\n* [Andres Coronado](https://www.linkedin.com/in/invzz) - Senior Software Engineer at Blue Star Software srl\\n* [Sebastiano Benfenati](https://www.linkedin.com/in/sebastiano-benfenati) - Hi, I\'m a Computer Engineering graduate from Italy, currently working on LGVs with various programming languages. Always seeking new challenges and ready to step out of my comfort zone to drive growth.", "score": 0.7707586}, {"title": "20+ \\"Riccardo Gioia\\" profiles - LinkedIn", "url": "https://www.linkedin.com/pub/dir/Riccardo/Gioia", "content": "Riccardo Gioia. Software Engineer presso Tron Group Holding. Parma. Tron Group Holding, +2 more. Università degli studi di Parma", "score": 0.734139}]', 'role': 'tool', 'tool_call_id': 'call_JBeAINBkTNsa18Tw2DWnrevk'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 12:16:23,296 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 12:16:23,297 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 12:16:23,299 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 12:16:23,299 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 12:16:23,301 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 12:16:23,303 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 12:16:23,846 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=594dd005-fe7f-461d-b8cf-9e5308c933a2; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=18354a15-cdf0-420d-ae21-729964a51094; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=b95d2c32-91f2-4e06-bee3-0786de8b93cc; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=57e65310-a8b5-46a6-b74f-3c1a76558fc9
2025-06-12 12:16:24,056 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:16:26,272 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 10:16:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'2735'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2741'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199572'), (b'x-ratelimit-reset-requests', b'14.083s'), (b'x-ratelimit-reset-tokens', b'128ms'), (b'x-request-id', b'req_ed80471aefb421db10d6a7a96afc427c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e897a4fae36130-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 12:16:26,276 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 12:16:26,278 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 12:16:26,281 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 12:16:26,282 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 12:16:26,283 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 12:16:26,286 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 10:16:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '2735', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2741', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199572', 'x-ratelimit-reset-requests': '14.083s', 'x-ratelimit-reset-tokens': '128ms', 'x-request-id': 'req_ed80471aefb421db10d6a7a96afc427c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e897a4fae36130-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 12:16:26,288 - openai._base_client - DEBUG - request_id: req_ed80471aefb421db10d6a7a96afc427c
2025-06-12 12:16:26,293 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 12:16:26,298 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 12:16:26,299 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 12:16:26,299 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 12:16:26,300 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 12:16:26,300 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 12:16:26,300 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 12:16:26,301 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 12:16:26,303 - src.agent - INFO - FINAL RESPONSE: 787 characters
2025-06-12 12:16:26,834 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=57e65310-a8b5-46a6-b74f-3c1a76558fc9; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=31f93068-e28c-40fc-9e09-ee9174167213; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=31f93068-e28c-40fc-9e09-ee9174167213; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=b95d2c32-91f2-4e06-bee3-0786de8b93cc; trace=d10503d0-3809-4924-9b19-e0bca23a5512,id=d10503d0-3809-4924-9b19-e0bca23a5512
2025-06-12 12:16:26,994 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:16:49,297 - src.agent - INFO - PROCESSING QUERY: 'thank you. What was his name again?'
2025-06-12 12:16:49,300 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 12:16:49,303 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f0a95fb7-6639-4311-8b37-b9eaabf9909b', 'json_data': {'messages': [{'content': 'thank you. What was his name again?', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 12:16:49,304 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 12:16:49,305 - httpcore.connection - DEBUG - close.started
2025-06-12 12:16:49,305 - httpcore.connection - DEBUG - close.complete
2025-06-12 12:16:49,305 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 12:16:49,336 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B930EC0690>
2025-06-12 12:16:49,337 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B9056292E0> server_hostname='api.openai.com' timeout=None
2025-06-12 12:16:49,392 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B930F8FA80>
2025-06-12 12:16:49,393 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 12:16:49,394 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 12:16:49,394 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 12:16:49,395 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 12:16:49,395 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 12:16:49,847 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1,id=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1; trace=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1,id=3e823e55-3a3a-4913-a5d1-061aebcc896d; trace=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1,id=669373fe-664e-4f77-84ad-a64fdd4ed00b
2025-06-12 12:16:50,019 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:16:50,415 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 10:16:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'591'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'596'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199988'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_f08bcee79ff45a1e33a86490c8977820'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e898480eb0ea41-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 12:16:50,419 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 12:16:50,420 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 12:16:50,422 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 12:16:50,424 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 12:16:50,426 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 12:16:50,427 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 10:16:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '591', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '596', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199988', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_f08bcee79ff45a1e33a86490c8977820', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e898480eb0ea41-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 12:16:50,429 - openai._base_client - DEBUG - request_id: req_f08bcee79ff45a1e33a86490c8977820
2025-06-12 12:16:50,455 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 12:16:50,462 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 12:16:50,463 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 12:16:50,465 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 12:16:50,466 - src.agent - INFO - FINAL RESPONSE: 108 characters
2025-06-12 12:16:51,017 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1,id=669373fe-664e-4f77-84ad-a64fdd4ed00b; trace=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1,id=2cc4be39-30cb-4e26-9537-f7ae845177fb; trace=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1,id=2cc4be39-30cb-4e26-9537-f7ae845177fb; trace=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1,id=3e823e55-3a3a-4913-a5d1-061aebcc896d; trace=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1,id=a7d58530-ff74-4dc0-b0f9-96aa78c3d6f1
2025-06-12 12:16:51,172 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:17:21,290 - src.agent - INFO - PROCESSING QUERY: 'The guy I asked you about just now'
2025-06-12 12:17:21,293 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 12:17:21,296 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-61ca7cb6-bcdf-4088-acd1-09546b7ca98b', 'json_data': {'messages': [{'content': 'The guy I asked you about just now', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 12:17:21,297 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 12:17:21,297 - httpcore.connection - DEBUG - close.started
2025-06-12 12:17:21,298 - httpcore.connection - DEBUG - close.complete
2025-06-12 12:17:21,298 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 12:17:21,374 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B930EFCFC0>
2025-06-12 12:17:21,374 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B9056292E0> server_hostname='api.openai.com' timeout=None
2025-06-12 12:17:21,420 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B930ECC050>
2025-06-12 12:17:21,423 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 12:17:21,424 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 12:17:21,424 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 12:17:21,425 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 12:17:21,425 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 12:17:21,817 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=bf077a1c-f868-4831-8e25-2e05e65ded1e,id=bf077a1c-f868-4831-8e25-2e05e65ded1e; trace=bf077a1c-f868-4831-8e25-2e05e65ded1e,id=24333492-bc6b-4f29-b455-8faa8736e667; trace=bf077a1c-f868-4831-8e25-2e05e65ded1e,id=b4e0f2c6-943d-4129-b30f-2ada0d43576e
2025-06-12 12:17:21,988 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:17:23,116 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 10:17:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1063'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1075'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199988'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_a9108aab5b79da7432905bf46e8f9c40'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e899104870ea3c-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 12:17:23,118 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 12:17:23,120 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 12:17:23,131 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 12:17:23,132 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 12:17:23,133 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 12:17:23,134 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 10:17:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '1063', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1075', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199988', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_a9108aab5b79da7432905bf46e8f9c40', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e899104870ea3c-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 12:17:23,136 - openai._base_client - DEBUG - request_id: req_a9108aab5b79da7432905bf46e8f9c40
2025-06-12 12:17:23,141 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 12:17:23,146 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 12:17:23,146 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 12:17:23,147 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 12:17:23,147 - src.agent - INFO - FINAL RESPONSE: 232 characters
2025-06-12 12:17:23,713 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=bf077a1c-f868-4831-8e25-2e05e65ded1e,id=b4e0f2c6-943d-4129-b30f-2ada0d43576e; trace=bf077a1c-f868-4831-8e25-2e05e65ded1e,id=e34addc1-1a1e-4ecd-9054-d0c1141c6ad5; trace=bf077a1c-f868-4831-8e25-2e05e65ded1e,id=e34addc1-1a1e-4ecd-9054-d0c1141c6ad5; trace=bf077a1c-f868-4831-8e25-2e05e65ded1e,id=24333492-bc6b-4f29-b455-8faa8736e667; trace=bf077a1c-f868-4831-8e25-2e05e65ded1e,id=bf077a1c-f868-4831-8e25-2e05e65ded1e
2025-06-12 12:17:23,865 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:18:55,260 - langsmith.client - DEBUG - Main thread is dead, stopping compression thread
2025-06-12 12:18:55,261 - langsmith.client - DEBUG - Compressed traces control thread is shutting down
2025-06-12 12:18:55,342 - langsmith.client - DEBUG - Main thread is dead, stopping tracing thread
2025-06-12 12:18:55,343 - langsmith.client - DEBUG - Tracing control thread is shutting down
2025-06-12 12:18:55,344 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 12:18:55,769 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 12:19:03,207 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 12:19:03,208 - src.utils - INFO - Total documents loaded: 70
2025-06-12 12:19:03,211 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 12:19:06,701 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 12:19:07,091 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 12:19:07,092 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 12:19:07,093 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 12:19:07,270 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 12:19:07,400 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 12:19:07,539 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 12:19:07,678 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 12:19:07,835 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 12:19:07,971 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 12:19:08,110 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 12:19:08,376 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 12:19:08,544 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 12:19:08,691 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 12:19:08,721 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 12:19:08,766 - chromadb.config - DEBUG - Starting component System
2025-06-12 12:19:08,766 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 12:19:09,293 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 12:19:09,666 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 12:19:11,608 - src.tools - INFO - Vector store initialized successfully
2025-06-12 12:19:11,631 - src.tools - INFO - Database connection established
2025-06-12 12:19:11,631 - src.tools - INFO - All tools initialized successfully
2025-06-12 12:19:11,631 - src.tools - INFO - Web search tool created successfully
2025-06-12 12:19:11,632 - src.tools - INFO - Web search tool available
2025-06-12 12:19:11,632 - src.tools - INFO - Document retrieval tool available
2025-06-12 12:19:11,632 - src.tools - INFO - SQL tool available
2025-06-12 12:19:11,632 - src.tools - INFO - Total available tools: 3
2025-06-12 12:19:11,638 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 12:19:55,023 - src.agent - INFO - PROCESSING QUERY: 'search on the internet if you can find any info about Riccardo Gioia, a software engineer'
2025-06-12 12:19:55,032 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443
2025-06-12 12:19:55,238 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "GET /info HTTP/1.1" 200 748
2025-06-12 12:19:55,316 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 12:19:55,320 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-8946e66d-84bd-4c79-9215-758e3ed289c0', 'json_data': {'messages': [{'content': 'search on the internet if you can find any info about Riccardo Gioia, a software engineer', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 12:19:55,321 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 12:19:55,321 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 12:19:55,378 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EABC6ECD70>
2025-06-12 12:19:55,379 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EAFFDB52E0> server_hostname='api.openai.com' timeout=None
2025-06-12 12:19:55,433 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EABC77DD10>
2025-06-12 12:19:55,433 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 12:19:55,434 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 12:19:55,434 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 12:19:55,434 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 12:19:55,435 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 12:19:55,866 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=efc55b99-d43c-44ad-a958-d606d1e2baf7; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=b80fdbdf-bf89-4d70-a2ec-619f9e8ec8a7; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=5c62252b-65f4-477e-b0d9-926e4ce8708a
2025-06-12 12:19:56,035 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:19:56,654 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 10:19:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'781'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'792'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199975'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7ms'), (b'x-request-id', b'req_77e5c52d7977fed3f9ac3faedca9d658'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=rLVEj_wocNGbSyINOZr7GsTRylc78RKeF.9ZD7Rz8w8-1749723595-1.0.1.1-08X6gk8wBlGo5zhH5EmhmGEkuthCaXGF5cyve.ZYbtr0v.qsibOrOMYp0YoLor9r.Ou.dsf6.luoZpbMyimG2iWwVh50_AUnrvVvgWWFXp0; path=/; expires=Thu, 12-Jun-25 10:49:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=l3SblRhwWfatr7hbCsbdEs3eXDVnIzZpFkGfVTNy_BI-1749723595883-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e89cd2cb5ade75-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 12:19:56,658 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 12:19:56,659 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 12:19:56,662 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 12:19:56,662 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 12:19:56,663 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 12:19:56,664 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 12 Jun 2025 10:19:55 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'politecnico-di-torino-bgszq8'), ('openai-processing-ms', '781'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '792'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199975'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '7ms'), ('x-request-id', 'req_77e5c52d7977fed3f9ac3faedca9d658'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=rLVEj_wocNGbSyINOZr7GsTRylc78RKeF.9ZD7Rz8w8-1749723595-1.0.1.1-08X6gk8wBlGo5zhH5EmhmGEkuthCaXGF5cyve.ZYbtr0v.qsibOrOMYp0YoLor9r.Ou.dsf6.luoZpbMyimG2iWwVh50_AUnrvVvgWWFXp0; path=/; expires=Thu, 12-Jun-25 10:49:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=l3SblRhwWfatr7hbCsbdEs3eXDVnIzZpFkGfVTNy_BI-1749723595883-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94e89cd2cb5ade75-FCO'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-12 12:19:56,665 - openai._base_client - DEBUG - request_id: req_77e5c52d7977fed3f9ac3faedca9d658
2025-06-12 12:19:56,688 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 12:19:56,702 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.tavily.com:443
2025-06-12 12:19:57,234 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=5c62252b-65f4-477e-b0d9-926e4ce8708a; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=fe1c3e5b-e2ad-4d1a-8746-134910129a84; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=fe1c3e5b-e2ad-4d1a-8746-134910129a84; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=b80fdbdf-bf89-4d70-a2ec-619f9e8ec8a7; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=472176f7-620d-4290-9091-7bc31c40c2af; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=f959af52-40b1-4435-a9e7-aaf2deca4684
2025-06-12 12:19:57,401 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:19:58,877 - urllib3.connectionpool - DEBUG - https://api.tavily.com:443 "POST /search HTTP/1.1" 200 1757
2025-06-12 12:19:58,880 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 12:19:58,882 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-5c789cf3-443d-4e51-9c7a-ffdeba0f48fe', 'json_data': {'messages': [{'content': 'search on the internet if you can find any info about Riccardo Gioia, a software engineer', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_IF0AW5MuYbiaJ9aZo2E8rhn4', 'function': {'name': 'tavily_search_results_json', 'arguments': '{"query": "Riccardo Gioia software engineer"}'}}]}, {'content': '[{"title": "Riccardo Gioia - Full-stack Developer - Tron Group Holding | LinkedIn", "url": "https://it.linkedin.com/in/riccardo-gioia-8b342a313", "content": "# Riccardo Gioia\\n**Software Engineer presso Tron Group Holding**  \\nParma, Italy  \\n60 connections, 60 followers\\n\\n## About\\nN/A [...] ## Education\\n### Università degli Studi di Parma  \\n Laurea in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n### Università degli Studi di Parma  \\n Laurea Magistrale in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n## Skills\\n**Front End Engineering Design (FEED)**, **Tecnologie Web**, **Settore software**, **Progettazione software**, **Java**, **Sviluppo Web**, **Sviluppo front-end**\\n\\n## Certifications\\nN/A\\n\\n## Volunteer Work\\nN/A\\n\\n## Languages\\nN/A\\n\\n## Groups\\nN/A [...] * [Marco Todaro](https://www.linkedin.com/in/marc0todar0) - Software Engineer presso Wide Group SpA.\\n* [Andres Coronado](https://www.linkedin.com/in/invzz) - Senior Software Engineer at Blue Star Software srl\\n* [Sebastiano Benfenati](https://www.linkedin.com/in/sebastiano-benfenati) - Hi, I\'m a Computer Engineering graduate from Italy, currently working on LGVs with various programming languages. Always seeking new challenges and ready to step out of my comfort zone to drive growth.", "score": 0.7707586}, {"title": "20+ \\"Riccardo Gioia\\" profiles - LinkedIn", "url": "https://www.linkedin.com/pub/dir/Riccardo/Gioia", "content": "Riccardo Gioia. Software Engineer presso Tron Group Holding. Parma. Tron Group Holding, +2 more. Università degli studi di Parma", "score": 0.734139}]', 'role': 'tool', 'tool_call_id': 'call_IF0AW5MuYbiaJ9aZo2E8rhn4'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 12:19:58,882 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 12:19:58,883 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 12:19:58,883 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 12:19:58,884 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 12:19:58,884 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 12:19:58,884 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 12:19:59,446 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=f959af52-40b1-4435-a9e7-aaf2deca4684; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=472176f7-620d-4290-9091-7bc31c40c2af; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=72d88a05-31f9-418f-9855-d2beef6880cf; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=9fdfdaad-324c-4461-83c4-8b61821b1b96
2025-06-12 12:19:59,608 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:20:03,662 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 10:20:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'4530'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4534'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199571'), (b'x-ratelimit-reset-requests', b'14.023s'), (b'x-ratelimit-reset-tokens', b'128ms'), (b'x-request-id', b'req_3f51addb8593420a1d9fff6ef7f18c20'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e89ce85a2dde75-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 12:20:03,666 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 12:20:03,668 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 12:20:03,671 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 12:20:03,673 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 12:20:03,675 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 12:20:03,676 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 10:20:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '4530', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4534', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199571', 'x-ratelimit-reset-requests': '14.023s', 'x-ratelimit-reset-tokens': '128ms', 'x-request-id': 'req_3f51addb8593420a1d9fff6ef7f18c20', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e89ce85a2dde75-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 12:20:03,679 - openai._base_client - DEBUG - request_id: req_3f51addb8593420a1d9fff6ef7f18c20
2025-06-12 12:20:03,684 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 12:20:03,691 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 12:20:03,692 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 12:20:03,694 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 12:20:03,695 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 12:20:03,696 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 12:20:03,697 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 12:20:03,697 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 12:20:03,698 - src.agent - INFO - FINAL RESPONSE: 917 characters
2025-06-12 12:20:04,231 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=9fdfdaad-324c-4461-83c4-8b61821b1b96; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=2c218ce0-a882-41c4-ad24-a1ec153a22c9; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=2c218ce0-a882-41c4-ad24-a1ec153a22c9; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=72d88a05-31f9-418f-9855-d2beef6880cf; trace=efc55b99-d43c-44ad-a958-d606d1e2baf7,id=efc55b99-d43c-44ad-a958-d606d1e2baf7
2025-06-12 12:20:04,405 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:20:23,277 - src.agent - INFO - PROCESSING QUERY: 'what was his name again?'
2025-06-12 12:20:23,279 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 12:20:23,281 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-eb88b2e8-7121-4e46-9667-747c78272ecc', 'json_data': {'messages': [{'content': 'what was his name again?', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 12:20:23,282 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 12:20:23,282 - httpcore.connection - DEBUG - close.started
2025-06-12 12:20:23,283 - httpcore.connection - DEBUG - close.complete
2025-06-12 12:20:23,283 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 12:20:23,320 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EABC6BC410>
2025-06-12 12:20:23,321 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EAFFDB52E0> server_hostname='api.openai.com' timeout=None
2025-06-12 12:20:23,368 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EABC783950>
2025-06-12 12:20:23,369 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 12:20:23,370 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 12:20:23,371 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 12:20:23,372 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 12:20:23,372 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 12:20:23,830 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=aba9dbec-06c0-41ce-8563-ac73f9fa51d7,id=aba9dbec-06c0-41ce-8563-ac73f9fa51d7; trace=aba9dbec-06c0-41ce-8563-ac73f9fa51d7,id=7fd98326-e14a-46d6-b576-7372bb070515; trace=aba9dbec-06c0-41ce-8563-ac73f9fa51d7,id=8b79e186-6883-4fc4-9ce8-c4af7267560f
2025-06-12 12:20:24,020 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:20:24,207 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 10:20:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'430'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199991'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_5a212f7bfb20e913643e9de0294a20fd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e89d816d9d77fa-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 12:20:24,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 12:20:24,209 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 12:20:24,210 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 12:20:24,210 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 12:20:24,211 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 12:20:24,211 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 10:20:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '427', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '430', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199991', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_5a212f7bfb20e913643e9de0294a20fd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e89d816d9d77fa-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 12:20:24,211 - openai._base_client - DEBUG - request_id: req_5a212f7bfb20e913643e9de0294a20fd
2025-06-12 12:20:24,222 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 12:20:24,224 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 12:20:24,225 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 12:20:24,225 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 12:20:24,225 - src.agent - INFO - FINAL RESPONSE: 81 characters
2025-06-12 12:20:24,757 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=aba9dbec-06c0-41ce-8563-ac73f9fa51d7,id=8b79e186-6883-4fc4-9ce8-c4af7267560f; trace=aba9dbec-06c0-41ce-8563-ac73f9fa51d7,id=4ed3aad4-0c26-4846-a14f-7a4fb14ba871; trace=aba9dbec-06c0-41ce-8563-ac73f9fa51d7,id=4ed3aad4-0c26-4846-a14f-7a4fb14ba871; trace=aba9dbec-06c0-41ce-8563-ac73f9fa51d7,id=7fd98326-e14a-46d6-b576-7372bb070515; trace=aba9dbec-06c0-41ce-8563-ac73f9fa51d7,id=aba9dbec-06c0-41ce-8563-ac73f9fa51d7
2025-06-12 12:20:24,930 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 12:46:04,297 - langsmith.client - DEBUG - Main thread is dead, stopping compression thread
2025-06-12 12:46:04,298 - langsmith.client - DEBUG - Compressed traces control thread is shutting down
2025-06-12 12:46:04,380 - langsmith.client - DEBUG - Main thread is dead, stopping tracing thread
2025-06-12 12:46:04,381 - langsmith.client - DEBUG - Tracing control thread is shutting down
2025-06-12 12:46:04,385 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 12:46:04,871 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 13:02:21,182 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 13:02:21,182 - src.utils - INFO - Total documents loaded: 70
2025-06-12 13:02:21,185 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 13:02:24,794 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 13:02:25,222 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 13:02:25,223 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 13:02:25,226 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 13:02:25,770 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 13:02:25,903 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 13:02:26,031 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 13:02:26,165 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 13:02:26,299 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 13:02:26,466 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 13:02:26,630 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 13:02:27,000 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 13:02:27,182 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 13:02:27,346 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 13:02:27,384 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 13:02:27,422 - chromadb.config - DEBUG - Starting component System
2025-06-12 13:02:27,422 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 13:02:27,950 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 13:02:28,366 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 13:02:30,524 - src.tools - INFO - Vector store initialized successfully
2025-06-12 13:02:30,547 - src.tools - INFO - Database connection established
2025-06-12 13:02:30,547 - src.tools - INFO - All tools initialized successfully
2025-06-12 13:02:30,547 - src.tools - INFO - Web search tool created successfully
2025-06-12 13:02:30,548 - src.tools - INFO - Web search tool available
2025-06-12 13:02:30,548 - src.tools - INFO - Document retrieval tool available
2025-06-12 13:02:30,548 - src.tools - INFO - SQL tool available
2025-06-12 13:02:30,548 - src.tools - INFO - Total available tools: 3
2025-06-12 13:02:30,555 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 13:02:52,544 - src.agent - INFO - PROCESSING QUERY: 'search info on the internet about Riccardo Gioia, a software engineer'
2025-06-12 13:02:52,550 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443
2025-06-12 13:02:52,778 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "GET /info HTTP/1.1" 200 748
2025-06-12 13:02:52,849 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:02:52,852 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-328d0fd3-867b-42f7-bc57-80fcc3ea1816', 'json_data': {'messages': [{'content': 'search info on the internet about Riccardo Gioia, a software engineer', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:02:52,853 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:02:52,853 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:02:52,887 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000216561B8D70>
2025-06-12 13:02:52,888 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002162A999370> server_hostname='api.openai.com' timeout=None
2025-06-12 13:02:52,938 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021656241E50>
2025-06-12 13:02:52,938 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:02:52,940 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:02:52,940 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:02:52,941 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:02:52,941 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:02:53,375 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=4e026877-db53-4ade-9bdb-4e52a8a37a24; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=41fffe51-c753-48c8-8473-6a55068286bf; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=c9726608-e39e-473c-9a0f-d19310af4100
2025-06-12 13:02:53,559 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:02:54,059 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:02:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'734'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'736'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199980'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_10ce989055c738da7bd619c4299dff2b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Pp.pyUEWhj3mqPBtUCEKN2AtCe4nEPynZnxToZuruHE-1749726173-1.0.1.1-jyRgFfeFvPbCPSw8QZ4i3.J.fRZu2ZIB8iTm2QA4EJSh.NnRqQ5EMPsuC5.V3zLAF.SEW.N33bcBLS.8Xco89l7BtYruy3nHK5VIOTq_h88; path=/; expires=Thu, 12-Jun-25 11:32:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=cKpueNG5uYENgIcxe3U9jaPLcI_jS3tYJJcyR9Ez9nU-1749726173271-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8dbc01f92e889-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:02:54,065 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:02:54,068 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:02:54,071 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:02:54,072 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:02:54,073 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:02:54,075 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 12 Jun 2025 11:02:53 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'politecnico-di-torino-bgszq8'), ('openai-processing-ms', '734'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '736'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199980'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_10ce989055c738da7bd619c4299dff2b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Pp.pyUEWhj3mqPBtUCEKN2AtCe4nEPynZnxToZuruHE-1749726173-1.0.1.1-jyRgFfeFvPbCPSw8QZ4i3.J.fRZu2ZIB8iTm2QA4EJSh.NnRqQ5EMPsuC5.V3zLAF.SEW.N33bcBLS.8Xco89l7BtYruy3nHK5VIOTq_h88; path=/; expires=Thu, 12-Jun-25 11:32:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=cKpueNG5uYENgIcxe3U9jaPLcI_jS3tYJJcyR9Ez9nU-1749726173271-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94e8dbc01f92e889-FCO'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-12 13:02:54,077 - openai._base_client - DEBUG - request_id: req_10ce989055c738da7bd619c4299dff2b
2025-06-12 13:02:54,102 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:02:54,106 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.tavily.com:443
2025-06-12 13:02:54,631 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=c9726608-e39e-473c-9a0f-d19310af4100; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=6dbb8105-a3dd-4b78-9fa4-3bc05ec41036; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=6dbb8105-a3dd-4b78-9fa4-3bc05ec41036; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=41fffe51-c753-48c8-8473-6a55068286bf; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=7ed0c21c-d524-4251-9f3a-b5adf008c202; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=6331c47f-09da-494c-b9c5-61a07d76c203
2025-06-12 13:02:54,803 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:02:56,714 - urllib3.connectionpool - DEBUG - https://api.tavily.com:443 "POST /search HTTP/1.1" 200 1758
2025-06-12 13:02:56,718 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:02:56,724 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-235a2820-9269-43fe-b909-a6617c07e26c', 'json_data': {'messages': [{'content': 'search info on the internet about Riccardo Gioia, a software engineer', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_xK44x3qEBMGPFzN5dhI0EoL1', 'function': {'name': 'tavily_search_results_json', 'arguments': '{"query": "Riccardo Gioia software engineer"}'}}]}, {'content': '[{"title": "Riccardo Gioia - Full-stack Developer - Tron Group Holding | LinkedIn", "url": "https://it.linkedin.com/in/riccardo-gioia-8b342a313", "content": "# Riccardo Gioia\\n**Software Engineer presso Tron Group Holding**  \\nParma, Italy  \\n60 connections, 60 followers\\n\\n## About\\nN/A [...] ## Education\\n### Università degli Studi di Parma  \\n Laurea in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n### Università degli Studi di Parma  \\n Laurea Magistrale in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n## Skills\\n**Front End Engineering Design (FEED)**, **Tecnologie Web**, **Settore software**, **Progettazione software**, **Java**, **Sviluppo Web**, **Sviluppo front-end**\\n\\n## Certifications\\nN/A\\n\\n## Volunteer Work\\nN/A\\n\\n## Languages\\nN/A\\n\\n## Groups\\nN/A [...] * [Marco Todaro](https://www.linkedin.com/in/marc0todar0) - Software Engineer presso Wide Group SpA.\\n* [Andres Coronado](https://www.linkedin.com/in/invzz) - Senior Software Engineer at Blue Star Software srl\\n* [Sebastiano Benfenati](https://www.linkedin.com/in/sebastiano-benfenati) - Hi, I\'m a Computer Engineering graduate from Italy, currently working on LGVs with various programming languages. Always seeking new challenges and ready to step out of my comfort zone to drive growth.", "score": 0.7707586}, {"title": "20+ \\"Riccardo Gioia\\" profiles - LinkedIn", "url": "https://www.linkedin.com/pub/dir/Riccardo/Gioia", "content": "Riccardo Gioia. Software Engineer presso Tron Group Holding. Parma. Tron Group Holding, +2 more. Università degli studi di Parma", "score": 0.734139}]', 'role': 'tool', 'tool_call_id': 'call_xK44x3qEBMGPFzN5dhI0EoL1'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:02:56,728 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:02:56,730 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:02:56,730 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:02:56,731 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:02:56,732 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:02:56,732 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:02:57,245 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=6331c47f-09da-494c-b9c5-61a07d76c203; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=7ed0c21c-d524-4251-9f3a-b5adf008c202; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=aca57fdf-c6e5-42fe-afbf-f63f2a8ba33a; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=711ac458-487f-4ea1-9361-4f9717a090fa
2025-06-12 13:02:57,411 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:03:03,091 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:03:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'5978'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5980'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199577'), (b'x-ratelimit-reset-requests', b'13.483s'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_1256e3c7bf43a30e6e2e5f29efd52ba5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8dbd7cb4fe889-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:03:03,095 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:03:03,097 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:03:03,099 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:03:03,101 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:03:03,102 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:03:03,104 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:03:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '5978', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5980', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199577', 'x-ratelimit-reset-requests': '13.483s', 'x-ratelimit-reset-tokens': '126ms', 'x-request-id': 'req_1256e3c7bf43a30e6e2e5f29efd52ba5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8dbd7cb4fe889-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:03:03,105 - openai._base_client - DEBUG - request_id: req_1256e3c7bf43a30e6e2e5f29efd52ba5
2025-06-12 13:03:03,111 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:03:03,116 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 13:03:03,117 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:03:03,118 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:03:03,118 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 13:03:03,118 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 13:03:03,119 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 13:03:03,119 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:03:03,120 - src.agent - INFO - FINAL RESPONSE: 1116 characters
2025-06-12 13:03:03,665 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=711ac458-487f-4ea1-9361-4f9717a090fa; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=ebce5d82-64c1-40a1-961c-fb27365d351e; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=ebce5d82-64c1-40a1-961c-fb27365d351e; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=aca57fdf-c6e5-42fe-afbf-f63f2a8ba33a; trace=4e026877-db53-4ade-9bdb-4e52a8a37a24,id=4e026877-db53-4ade-9bdb-4e52a8a37a24
2025-06-12 13:03:03,842 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:03:16,045 - src.agent - INFO - PROCESSING QUERY: 'what was his name again?'
2025-06-12 13:03:16,048 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:03:16,051 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f6cdd88a-868a-4d37-9437-4d1cd0f7e9f8', 'json_data': {'messages': [{'content': 'what was his name again?', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:03:16,052 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:03:16,053 - httpcore.connection - DEBUG - close.started
2025-06-12 13:03:16,053 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:03:16,053 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:03:16,084 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021656180550>
2025-06-12 13:03:16,084 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002162A999370> server_hostname='api.openai.com' timeout=None
2025-06-12 13:03:16,131 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002165623FCE0>
2025-06-12 13:03:16,134 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:03:16,136 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:03:16,137 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:03:16,139 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:03:16,140 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:03:16,598 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=97f01cd2-40e2-4980-990a-3975e905e64b,id=97f01cd2-40e2-4980-990a-3975e905e64b; trace=97f01cd2-40e2-4980-990a-3975e905e64b,id=368596e0-6e9c-4cf7-8c47-a004a5445ee8; trace=97f01cd2-40e2-4980-990a-3975e905e64b,id=e4cef301-22a7-4989-8c71-7915bb486ba0
2025-06-12 13:03:16,791 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:03:17,808 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:03:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1458'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1461'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199992'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_fea13981b2f9d2de0969a6d589a8c0c8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8dc511e96ea39-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:03:17,810 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:03:17,811 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:03:17,813 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:03:17,815 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:03:17,817 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:03:17,818 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:03:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '1458', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1461', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199992', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_fea13981b2f9d2de0969a6d589a8c0c8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8dc511e96ea39-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:03:17,819 - openai._base_client - DEBUG - request_id: req_fea13981b2f9d2de0969a6d589a8c0c8
2025-06-12 13:03:17,823 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:03:17,832 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:03:17,835 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:03:17,837 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:03:17,839 - src.agent - INFO - FINAL RESPONSE: 109 characters
2025-06-12 13:03:18,376 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=97f01cd2-40e2-4980-990a-3975e905e64b,id=e4cef301-22a7-4989-8c71-7915bb486ba0; trace=97f01cd2-40e2-4980-990a-3975e905e64b,id=d594014a-bb51-4118-ab32-3b523af74514; trace=97f01cd2-40e2-4980-990a-3975e905e64b,id=d594014a-bb51-4118-ab32-3b523af74514; trace=97f01cd2-40e2-4980-990a-3975e905e64b,id=368596e0-6e9c-4cf7-8c47-a004a5445ee8; trace=97f01cd2-40e2-4980-990a-3975e905e64b,id=97f01cd2-40e2-4980-990a-3975e905e64b
2025-06-12 13:03:18,557 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:03:33,227 - src.agent - INFO - PROCESSING QUERY: 'the guy we discussed about previously'
2025-06-12 13:03:33,230 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:03:33,231 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d4a75b67-64da-487f-a1c9-6786cc88964a', 'json_data': {'messages': [{'content': 'the guy we discussed about previously', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:03:33,233 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:03:33,233 - httpcore.connection - DEBUG - close.started
2025-06-12 13:03:33,233 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:03:33,233 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:03:33,271 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000216561B16E0>
2025-06-12 13:03:33,272 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002162A999370> server_hostname='api.openai.com' timeout=None
2025-06-12 13:03:33,320 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002165617C050>
2025-06-12 13:03:33,322 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:03:33,324 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:03:33,325 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:03:33,326 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:03:33,328 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:03:33,771 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=b91c3064-bf0c-4906-8007-d2d4f4cf67ba; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=012b07b0-60e6-4b62-94a9-163b592b23fe; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=1223c660-9be9-471e-80e9-6c5dc44319f4
2025-06-12 13:03:33,931 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:03:34,127 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:03:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'571'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'573'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199987'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_cdf1471ec300d5ed258ebe1fc4ab7a73'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8dcbc8a109468-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:03:34,130 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:03:34,132 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:03:34,134 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:03:34,136 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:03:34,137 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:03:34,138 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:03:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '571', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '573', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199987', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_cdf1471ec300d5ed258ebe1fc4ab7a73', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8dcbc8a109468-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:03:34,141 - openai._base_client - DEBUG - request_id: req_cdf1471ec300d5ed258ebe1fc4ab7a73
2025-06-12 13:03:34,167 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:03:34,175 - src.tools - INFO - DOCUMENT RETRIEVAL TOOL CALLED with question: the guy we discussed about previously
2025-06-12 13:03:34,314 - src.tools - INFO - DOCUMENT RETRIEVAL RESULT: 1632 characters, 2 documents
2025-06-12 13:03:34,334 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:03:34,335 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-be0428a6-ed08-41bf-a314-4de68a921747', 'json_data': {'messages': [{'content': 'the guy we discussed about previously', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_WHwpFy3V1uttBUH54Gn7v8w7', 'function': {'name': 'retriever_tool', 'arguments': '{"question": "the guy we discussed about previously"}'}}]}, {'content': 'While this model provides a foundation for flu forecasting in Italy, there is still plenty\nofroomtorefineit. Whetherthatmeanssimplifyingsomecomponents, addingmoredata,\nor finding new ways to estimate parameters, there is a lot to explore in the intersection\nbetween epidemiological modeling and data science.\nI am personally quite curious to see what the future holds, and if my works serves\nas a small step in the right direction, whether that means helping real people in their\nreal-life problems using mathematics or simply advancing human knowledge, I will be\ndeeply satisfied. Once again, my acknowledgements go to everyone that helped my in\nthis long journey, and I should especially thank Lorenzo, Alessandro and Elisa, without\nthem I would not have had the occasion to work on such a stimulating project.\n46\n\nWhile this model provides a foundation for flu forecasting in Italy, there is still plenty\nofroomtorefineit. Whetherthatmeanssimplifyingsomecomponents, addingmoredata,\nor finding new ways to estimate parameters, there is a lot to explore in the intersection\nbetween epidemiological modeling and data science.\nI am personally quite curious to see what the future holds, and if my works serves\nas a small step in the right direction, whether that means helping real people in their\nreal-life problems using mathematics or simply advancing human knowledge, I will be\ndeeply satisfied. Once again, my acknowledgements go to everyone that helped my in\nthis long journey, and I should especially thank Lorenzo, Alessandro and Elisa, without\nthem I would not have had the occasion to work on such a stimulating project.\n46', 'role': 'tool', 'tool_call_id': 'call_WHwpFy3V1uttBUH54Gn7v8w7'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:03:34,336 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:03:34,337 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:03:34,337 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:03:34,337 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:03:34,337 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:03:34,337 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:03:34,696 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 13:03:34,884 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=1223c660-9be9-471e-80e9-6c5dc44319f4; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=a51df2e9-13d7-4d4a-b26a-c29ae5870b63; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=a51df2e9-13d7-4d4a-b26a-c29ae5870b63; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=012b07b0-60e6-4b62-94a9-163b592b23fe; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=a3bce8d6-eddf-4f47-b9e6-2247bfdb6b89; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=94cbecc8-a520-4cfe-92ad-34095f56903f; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=4e6c941a-bffa-435a-8468-0478fa12e7cf; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=4e6c941a-bffa-435a-8468-0478fa12e7cf; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=94cbecc8-a520-4cfe-92ad-34095f56903f; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=a3bce8d6-eddf-4f47-b9e6-2247bfdb6b89; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=86ac093b-adec-452d-830b-4e0c5adb2cb0; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=c86986d5-3a80-4fd7-a6e3-210c100f2d41
2025-06-12 13:03:35,068 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:03:36,760 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:03:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'2019'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'2022'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199578'), (b'x-ratelimit-reset-requests', b'16.087s'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_3a16134845169494a36bec8fcad6ed59'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8dcc2fbba9468-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:03:36,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:03:36,761 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:03:36,761 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:03:36,761 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:03:36,761 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:03:36,761 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:03:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '2019', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '2022', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199578', 'x-ratelimit-reset-requests': '16.087s', 'x-ratelimit-reset-tokens': '126ms', 'x-request-id': 'req_3a16134845169494a36bec8fcad6ed59', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8dcc2fbba9468-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:03:36,761 - openai._base_client - DEBUG - request_id: req_3a16134845169494a36bec8fcad6ed59
2025-06-12 13:03:36,762 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:03:36,764 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 13:03:36,764 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:03:36,764 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:03:36,764 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 13:03:36,764 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 13:03:36,764 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 13:03:36,764 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:03:36,764 - src.agent - INFO - FINAL RESPONSE: 261 characters
2025-06-12 13:03:37,321 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=c86986d5-3a80-4fd7-a6e3-210c100f2d41; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=7ae7d8df-a087-468f-8ca3-2ebee9fcf5d6; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=7ae7d8df-a087-468f-8ca3-2ebee9fcf5d6; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=86ac093b-adec-452d-830b-4e0c5adb2cb0; trace=b91c3064-bf0c-4906-8007-d2d4f4cf67ba,id=b91c3064-bf0c-4906-8007-d2d4f4cf67ba
2025-06-12 13:03:37,496 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:05:29,067 - src.agent - INFO - PROCESSING QUERY: '& C:/Users/celin/AppData/Local/Programs/Python/Python313/python.exe c:/Users/celin/Desktop/algoverde/web_search_agent/main.py'
2025-06-12 13:05:29,068 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:05:29,070 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-0c5de870-3c77-4bf6-a79f-13a3c6d7536d', 'json_data': {'messages': [{'content': '& C:/Users/celin/AppData/Local/Programs/Python/Python313/python.exe c:/Users/celin/Desktop/algoverde/web_search_agent/main.py', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:05:29,070 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:05:29,070 - httpcore.connection - DEBUG - close.started
2025-06-12 13:05:29,071 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:05:29,071 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:05:29,107 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000216550019D0>
2025-06-12 13:05:29,108 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002162A999370> server_hostname='api.openai.com' timeout=None
2025-06-12 13:05:29,153 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021655001AE0>
2025-06-12 13:05:29,154 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:05:29,155 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:05:29,155 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:05:29,156 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:05:29,156 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:05:29,631 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=fa79aa9f-1654-459f-962c-090aef78cf1a,id=fa79aa9f-1654-459f-962c-090aef78cf1a; trace=fa79aa9f-1654-459f-962c-090aef78cf1a,id=0b6bb1af-e2a2-4715-b1d4-a6b5ff0ec321; trace=fa79aa9f-1654-459f-962c-090aef78cf1a,id=703f0e2d-a00f-4a53-8603-80ca694e43e8
2025-06-12 13:05:29,819 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:05:33,376 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:05:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'4013'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'4017'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199966'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_4e33dd3dafcb9b2a8777401fae4c04d9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8df906b6fea69-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:05:33,378 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:05:33,378 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:05:33,380 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:05:33,380 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:05:33,381 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:05:33,382 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:05:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '4013', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '4017', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199966', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '10ms', 'x-request-id': 'req_4e33dd3dafcb9b2a8777401fae4c04d9', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8df906b6fea69-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:05:33,382 - openai._base_client - DEBUG - request_id: req_4e33dd3dafcb9b2a8777401fae4c04d9
2025-06-12 13:05:33,384 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:05:33,388 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:05:33,389 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:05:33,389 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:05:33,389 - src.agent - INFO - FINAL RESPONSE: 666 characters
2025-06-12 13:05:33,920 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=fa79aa9f-1654-459f-962c-090aef78cf1a,id=703f0e2d-a00f-4a53-8603-80ca694e43e8; trace=fa79aa9f-1654-459f-962c-090aef78cf1a,id=495026b4-9726-4a67-9985-8a0eb80256d8; trace=fa79aa9f-1654-459f-962c-090aef78cf1a,id=495026b4-9726-4a67-9985-8a0eb80256d8; trace=fa79aa9f-1654-459f-962c-090aef78cf1a,id=0b6bb1af-e2a2-4715-b1d4-a6b5ff0ec321; trace=fa79aa9f-1654-459f-962c-090aef78cf1a,id=fa79aa9f-1654-459f-962c-090aef78cf1a
2025-06-12 13:05:34,103 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:05:39,509 - langsmith.client - DEBUG - Main thread is dead, stopping compression thread
2025-06-12 13:05:39,509 - langsmith.client - DEBUG - Compressed traces control thread is shutting down
2025-06-12 13:05:39,592 - langsmith.client - DEBUG - Main thread is dead, stopping tracing thread
2025-06-12 13:05:39,594 - langsmith.client - DEBUG - Tracing control thread is shutting down
2025-06-12 13:05:39,597 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 13:05:39,977 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 13:05:57,181 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 13:05:57,182 - src.utils - INFO - Total documents loaded: 70
2025-06-12 13:05:57,185 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 13:06:00,567 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 13:06:00,971 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 13:06:00,972 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 13:06:00,973 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 13:06:01,215 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 13:06:01,344 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 13:06:01,536 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 13:06:01,672 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 13:06:01,813 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 13:06:01,981 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 13:06:02,370 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 13:06:02,657 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 13:06:02,839 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 13:06:03,132 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 13:06:03,163 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 13:06:03,199 - chromadb.config - DEBUG - Starting component System
2025-06-12 13:06:03,199 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 13:06:03,724 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 13:06:04,205 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 13:06:06,027 - src.tools - INFO - Vector store initialized successfully
2025-06-12 13:06:06,047 - src.tools - INFO - Database connection established
2025-06-12 13:06:06,047 - src.tools - INFO - All tools initialized successfully
2025-06-12 13:06:06,048 - src.tools - INFO - Web search tool created successfully
2025-06-12 13:06:06,048 - src.tools - INFO - Web search tool available
2025-06-12 13:06:06,048 - src.tools - INFO - Document retrieval tool available
2025-06-12 13:06:06,049 - src.tools - INFO - SQL tool available
2025-06-12 13:06:06,049 - src.tools - INFO - Total available tools: 3
2025-06-12 13:06:06,057 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 13:06:23,217 - src.agent - INFO - PROCESSING QUERY: 'search info on the internet about Riccardo Gioia, a software engineer'
2025-06-12 13:06:23,225 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443
2025-06-12 13:06:23,407 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "GET /info HTTP/1.1" 200 748
2025-06-12 13:06:23,476 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:06:23,480 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-427c03a3-0152-4227-aa95-bca780e50e2c', 'json_data': {'messages': [{'content': 'search info on the internet about Riccardo Gioia, a software engineer', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:06:23,481 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:06:23,481 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:06:23,535 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012DCED58D70>
2025-06-12 13:06:23,535 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000012DA3549370> server_hostname='api.openai.com' timeout=None
2025-06-12 13:06:23,621 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012DCEDE20D0>
2025-06-12 13:06:23,623 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:06:23,624 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:06:23,624 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:06:23,625 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:06:23,625 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:06:23,997 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=76e9304e-88ac-43a0-886c-33a22e35f373; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=458a377c-e172-4679-b2d0-25de781bd559; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=0c3f9624-8376-4704-b3bb-d1ed7e342d10
2025-06-12 13:06:24,177 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:06:25,520 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1267'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1270'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199980'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_4cbc995e3e6f9788f1bc447341e27bf0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ta00Id__fDJRcjHlU1nPyC76k6mvVjUpupwi9Bn2E3w-1749726384-1.0.1.1-qi4d8owwmXWCz7.LgNCEc.cLoLFQLR2e4xLBckULz41I8.e9bBgCMR7KI272KoRThF6RmIi2auGFZkVjRdss8du1nJt0IvODvZBcpOEupdk; path=/; expires=Thu, 12-Jun-25 11:36:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=GvVEyiiTYEFkGSb2Ir946prFV2K.KNLInieNWnFS3ww-1749726384700-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8e0e50a7dea59-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:06:25,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:06:25,529 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:06:25,532 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:06:25,534 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:06:25,535 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:06:25,537 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 12 Jun 2025 11:06:24 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'politecnico-di-torino-bgszq8'), ('openai-processing-ms', '1267'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '1270'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199980'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_4cbc995e3e6f9788f1bc447341e27bf0'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Ta00Id__fDJRcjHlU1nPyC76k6mvVjUpupwi9Bn2E3w-1749726384-1.0.1.1-qi4d8owwmXWCz7.LgNCEc.cLoLFQLR2e4xLBckULz41I8.e9bBgCMR7KI272KoRThF6RmIi2auGFZkVjRdss8du1nJt0IvODvZBcpOEupdk; path=/; expires=Thu, 12-Jun-25 11:36:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=GvVEyiiTYEFkGSb2Ir946prFV2K.KNLInieNWnFS3ww-1749726384700-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94e8e0e50a7dea59-FCO'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-12 13:06:25,539 - openai._base_client - DEBUG - request_id: req_4cbc995e3e6f9788f1bc447341e27bf0
2025-06-12 13:06:25,556 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:06:25,567 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.tavily.com:443
2025-06-12 13:06:26,107 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=0c3f9624-8376-4704-b3bb-d1ed7e342d10; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=d625e4df-96fe-4c72-9fed-d79761daa392; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=d625e4df-96fe-4c72-9fed-d79761daa392; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=458a377c-e172-4679-b2d0-25de781bd559; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=282a2923-ba8f-403c-99b2-d8ac0e38f63c; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=4d115aa7-e001-498e-871c-42e88e86a2c4
2025-06-12 13:06:26,278 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:06:27,270 - urllib3.connectionpool - DEBUG - https://api.tavily.com:443 "POST /search HTTP/1.1" 200 1758
2025-06-12 13:06:27,275 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:06:27,279 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-47d52235-6b2e-40a1-8ebf-63713720650d', 'json_data': {'messages': [{'content': 'search info on the internet about Riccardo Gioia, a software engineer', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_9XdwpTuwxKn9k6KF4w4hrMsB', 'function': {'name': 'tavily_search_results_json', 'arguments': '{"query": "Riccardo Gioia software engineer"}'}}]}, {'content': '[{"title": "Riccardo Gioia - Full-stack Developer - Tron Group Holding | LinkedIn", "url": "https://it.linkedin.com/in/riccardo-gioia-8b342a313", "content": "# Riccardo Gioia\\n**Software Engineer presso Tron Group Holding**  \\nParma, Italy  \\n60 connections, 60 followers\\n\\n## About\\nN/A [...] ## Education\\n### Università degli Studi di Parma  \\n Laurea in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n### Università degli Studi di Parma  \\n Laurea Magistrale in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n## Skills\\n**Front End Engineering Design (FEED)**, **Tecnologie Web**, **Settore software**, **Progettazione software**, **Java**, **Sviluppo Web**, **Sviluppo front-end**\\n\\n## Certifications\\nN/A\\n\\n## Volunteer Work\\nN/A\\n\\n## Languages\\nN/A\\n\\n## Groups\\nN/A [...] * [Marco Todaro](https://www.linkedin.com/in/marc0todar0) - Software Engineer presso Wide Group SpA.\\n* [Andres Coronado](https://www.linkedin.com/in/invzz) - Senior Software Engineer at Blue Star Software srl\\n* [Sebastiano Benfenati](https://www.linkedin.com/in/sebastiano-benfenati) - Hi, I\'m a Computer Engineering graduate from Italy, currently working on LGVs with various programming languages. Always seeking new challenges and ready to step out of my comfort zone to drive growth.", "score": 0.7707586}, {"title": "20+ \\"Riccardo Gioia\\" profiles - LinkedIn", "url": "https://www.linkedin.com/pub/dir/Riccardo/Gioia", "content": "Riccardo Gioia. Software Engineer presso Tron Group Holding. Parma. Tron Group Holding, +2 more. Università degli studi di Parma", "score": 0.734139}]', 'role': 'tool', 'tool_call_id': 'call_9XdwpTuwxKn9k6KF4w4hrMsB'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:06:27,281 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:06:27,282 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:06:27,283 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:06:27,283 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:06:27,284 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:06:27,284 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:06:27,839 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=4d115aa7-e001-498e-871c-42e88e86a2c4; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=282a2923-ba8f-403c-99b2-d8ac0e38f63c; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=282eb875-2645-4e74-95c9-845731363cfb; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=e78803c0-47b3-444c-b819-82134f3abc85
2025-06-12 13:06:28,029 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:06:33,356 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:06:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'5596'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'5600'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199577'), (b'x-ratelimit-reset-requests', b'13.735s'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_fdae8997832209d858219cf1c78c48ff'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8e0fbbe10ea59-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:06:33,361 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:06:33,363 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:06:33,365 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:06:33,367 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:06:33,368 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:06:33,369 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:06:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '5596', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '5600', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199577', 'x-ratelimit-reset-requests': '13.735s', 'x-ratelimit-reset-tokens': '126ms', 'x-request-id': 'req_fdae8997832209d858219cf1c78c48ff', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8e0fbbe10ea59-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:06:33,371 - openai._base_client - DEBUG - request_id: req_fdae8997832209d858219cf1c78c48ff
2025-06-12 13:06:33,374 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:06:33,379 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 13:06:33,380 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:06:33,381 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:06:33,381 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 13:06:33,382 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 13:06:33,383 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 13:06:33,383 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:06:33,383 - src.agent - INFO - FINAL RESPONSE: 877 characters
2025-06-12 13:06:33,904 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=e78803c0-47b3-444c-b819-82134f3abc85; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=c8e48ff0-b481-40e4-9a7f-713efbc36eb5; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=c8e48ff0-b481-40e4-9a7f-713efbc36eb5; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=282eb875-2645-4e74-95c9-845731363cfb; trace=76e9304e-88ac-43a0-886c-33a22e35f373,id=76e9304e-88ac-43a0-886c-33a22e35f373
2025-06-12 13:06:34,073 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:06:49,389 - src.agent - INFO - PROCESSING QUERY: 'what was his name again?'
2025-06-12 13:06:49,391 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:06:49,394 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-30023ed1-f3b7-471b-87ca-b790c25b3f32', 'json_data': {'messages': [{'content': 'what was his name again?', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:06:49,395 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:06:49,396 - httpcore.connection - DEBUG - close.started
2025-06-12 13:06:49,396 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:06:49,397 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:06:49,429 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012DCED14690>
2025-06-12 13:06:49,430 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000012DA3549370> server_hostname='api.openai.com' timeout=None
2025-06-12 13:06:49,481 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012DCEDBFCE0>
2025-06-12 13:06:49,482 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:06:49,484 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:06:49,484 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:06:49,485 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:06:49,488 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:06:49,931 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=1026ae6c-2e7f-4217-b6c9-17ea1fced74a,id=1026ae6c-2e7f-4217-b6c9-17ea1fced74a; trace=1026ae6c-2e7f-4217-b6c9-17ea1fced74a,id=2b579e4f-75d9-4b27-825d-091b4183b17b; trace=1026ae6c-2e7f-4217-b6c9-17ea1fced74a,id=52cd8f62-c5ba-4785-a262-ba84436542dd
2025-06-12 13:06:50,092 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:06:50,722 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:06:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1000'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1005'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199991'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_0241dd07d78221609cd2b8a4ae250cbd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8e1867acaea6f-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:06:50,725 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:06:50,726 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:06:50,728 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:06:50,729 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:06:50,731 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:06:50,732 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:06:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '1000', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1005', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199991', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_0241dd07d78221609cd2b8a4ae250cbd', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8e1867acaea6f-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:06:50,733 - openai._base_client - DEBUG - request_id: req_0241dd07d78221609cd2b8a4ae250cbd
2025-06-12 13:06:50,736 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:06:50,741 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:06:50,742 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:06:50,743 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:06:50,743 - src.agent - INFO - FINAL RESPONSE: 161 characters
2025-06-12 13:06:51,292 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=1026ae6c-2e7f-4217-b6c9-17ea1fced74a,id=52cd8f62-c5ba-4785-a262-ba84436542dd; trace=1026ae6c-2e7f-4217-b6c9-17ea1fced74a,id=5b69340d-0e63-4b7a-b8de-170fb31ede3e; trace=1026ae6c-2e7f-4217-b6c9-17ea1fced74a,id=5b69340d-0e63-4b7a-b8de-170fb31ede3e; trace=1026ae6c-2e7f-4217-b6c9-17ea1fced74a,id=2b579e4f-75d9-4b27-825d-091b4183b17b; trace=1026ae6c-2e7f-4217-b6c9-17ea1fced74a,id=1026ae6c-2e7f-4217-b6c9-17ea1fced74a
2025-06-12 13:06:51,459 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:06:55,534 - langsmith.client - DEBUG - Main thread is dead, stopping compression thread
2025-06-12 13:06:55,536 - langsmith.client - DEBUG - Compressed traces control thread is shutting down
2025-06-12 13:06:55,667 - langsmith.client - DEBUG - Main thread is dead, stopping tracing thread
2025-06-12 13:06:55,669 - langsmith.client - DEBUG - Tracing control thread is shutting down
2025-06-12 13:06:55,672 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 13:06:55,776 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 13:09:27,542 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 13:09:27,543 - src.utils - INFO - Total documents loaded: 70
2025-06-12 13:09:27,546 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 13:09:30,902 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 13:09:31,301 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 13:09:31,302 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 13:09:31,304 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 13:09:31,483 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 13:09:31,675 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 13:09:32,075 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 13:09:32,319 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 13:09:32,640 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 13:09:32,968 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 13:09:33,110 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 13:09:33,469 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 13:09:33,691 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 13:09:33,823 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 13:09:33,841 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 13:09:33,875 - chromadb.config - DEBUG - Starting component System
2025-06-12 13:09:33,876 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 13:09:34,398 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 13:09:34,850 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 13:09:36,623 - src.tools - INFO - Vector store initialized successfully
2025-06-12 13:09:36,653 - src.tools - INFO - Database connection established
2025-06-12 13:09:36,654 - src.tools - INFO - All tools initialized successfully
2025-06-12 13:09:36,654 - src.tools - INFO - Web search tool created successfully
2025-06-12 13:09:36,654 - src.tools - INFO - Web search tool available
2025-06-12 13:09:36,654 - src.tools - INFO - Document retrieval tool available
2025-06-12 13:09:36,655 - src.tools - INFO - SQL tool available
2025-06-12 13:09:36,655 - src.tools - INFO - Total available tools: 3
2025-06-12 13:09:36,663 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 13:09:51,176 - src.agent - INFO - PROCESSING QUERY: 'search info on the internet about Riccardo Gioia, a software engineer'
2025-06-12 13:09:51,185 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443
2025-06-12 13:09:51,378 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "GET /info HTTP/1.1" 200 748
2025-06-12 13:09:51,407 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:09:51,411 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fab699b2-2454-416b-becb-0c9f013c2f7e', 'json_data': {'messages': [{'content': 'search info on the internet about Riccardo Gioia, a software engineer', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:09:51,411 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:09:51,412 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:09:51,451 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002025F8CCEC0>
2025-06-12 13:09:51,454 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000202340F9370> server_hostname='api.openai.com' timeout=None
2025-06-12 13:09:51,512 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002025F951F90>
2025-06-12 13:09:51,513 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:09:51,514 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:09:51,514 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:09:51,515 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:09:51,516 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:09:51,959 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=0137dc25-d491-49ed-99ec-346dacce200c,id=0137dc25-d491-49ed-99ec-346dacce200c; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=66d7521e-b9ad-445e-a886-c81e0756f23c; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=4cdfddaa-0589-46a3-a438-137596255dd6
2025-06-12 13:09:52,124 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:09:52,610 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:09:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'890'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'892'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199980'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_7c2ba894d92941f4c275a14d05864ced'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LwtCDO_8hu9J61zoBPsUQHp_PZywtuMlXMe7VgsUfZg-1749726591-1.0.1.1-fWGSo_iD4KfwtJBUMj4B2bqTWfeaN3sT7a9DEksqcjBnXVBX74X5MDwwZAbIYUPgHlMron8oYVLOXo37shg_N_paA590f89Zz1KL0v6JtCw; path=/; expires=Thu, 12-Jun-25 11:39:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=qQDE0hbRIO.C6xBW1fkH2MqUZQKGVcNU.bvYM2lcjcU-1749726591820-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8e5f82cadea3d-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:09:52,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:09:52,617 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:09:52,619 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:09:52,619 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:09:52,620 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:09:52,622 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 12 Jun 2025 11:09:51 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'politecnico-di-torino-bgszq8'), ('openai-processing-ms', '890'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '892'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199980'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6ms'), ('x-request-id', 'req_7c2ba894d92941f4c275a14d05864ced'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=LwtCDO_8hu9J61zoBPsUQHp_PZywtuMlXMe7VgsUfZg-1749726591-1.0.1.1-fWGSo_iD4KfwtJBUMj4B2bqTWfeaN3sT7a9DEksqcjBnXVBX74X5MDwwZAbIYUPgHlMron8oYVLOXo37shg_N_paA590f89Zz1KL0v6JtCw; path=/; expires=Thu, 12-Jun-25 11:39:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=qQDE0hbRIO.C6xBW1fkH2MqUZQKGVcNU.bvYM2lcjcU-1749726591820-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94e8e5f82cadea3d-FCO'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-12 13:09:52,623 - openai._base_client - DEBUG - request_id: req_7c2ba894d92941f4c275a14d05864ced
2025-06-12 13:09:52,680 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:09:52,698 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.tavily.com:443
2025-06-12 13:09:53,240 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=0137dc25-d491-49ed-99ec-346dacce200c,id=4cdfddaa-0589-46a3-a438-137596255dd6; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=e8a19de6-7ae9-461d-bdef-f38ad9e5b0ac; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=e8a19de6-7ae9-461d-bdef-f38ad9e5b0ac; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=66d7521e-b9ad-445e-a886-c81e0756f23c; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=129a4c26-c3d1-48d3-bbc1-85d9866c6b4c; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=3f1a983d-945c-4aaf-8858-0bd8fde79585
2025-06-12 13:09:53,403 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:09:54,182 - urllib3.connectionpool - DEBUG - https://api.tavily.com:443 "POST /search HTTP/1.1" 200 1758
2025-06-12 13:09:54,188 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:09:54,190 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-29603c99-74a4-459f-8054-e44b9a12441e', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search info on the internet about Riccardo Gioia, a software engineer', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_hQEFgWAIpsnsF3MfRB03FZX5', 'function': {'name': 'tavily_search_results_json', 'arguments': '{"query": "Riccardo Gioia software engineer"}'}}]}, {'content': '[{"title": "Riccardo Gioia - Full-stack Developer - Tron Group Holding | LinkedIn", "url": "https://it.linkedin.com/in/riccardo-gioia-8b342a313", "content": "# Riccardo Gioia\\n**Software Engineer presso Tron Group Holding**  \\nParma, Italy  \\n60 connections, 60 followers\\n\\n## About\\nN/A [...] ## Education\\n### Università degli Studi di Parma  \\n Laurea in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n### Università degli Studi di Parma  \\n Laurea Magistrale in Informatica, Informatica  \\n N/A - Present  \\n N/A  \\n N/A\\n\\n## Skills\\n**Front End Engineering Design (FEED)**, **Tecnologie Web**, **Settore software**, **Progettazione software**, **Java**, **Sviluppo Web**, **Sviluppo front-end**\\n\\n## Certifications\\nN/A\\n\\n## Volunteer Work\\nN/A\\n\\n## Languages\\nN/A\\n\\n## Groups\\nN/A [...] * [Marco Todaro](https://www.linkedin.com/in/marc0todar0) - Software Engineer presso Wide Group SpA.\\n* [Andres Coronado](https://www.linkedin.com/in/invzz) - Senior Software Engineer at Blue Star Software srl\\n* [Sebastiano Benfenati](https://www.linkedin.com/in/sebastiano-benfenati) - Hi, I\'m a Computer Engineering graduate from Italy, currently working on LGVs with various programming languages. Always seeking new challenges and ready to step out of my comfort zone to drive growth.", "score": 0.7707586}, {"title": "20+ \\"Riccardo Gioia\\" profiles - LinkedIn", "url": "https://www.linkedin.com/pub/dir/Riccardo/Gioia", "content": "Riccardo Gioia. Software Engineer presso Tron Group Holding. Parma. Tron Group Holding, +2 more. Università degli studi di Parma", "score": 0.734139}]', 'role': 'tool', 'tool_call_id': 'call_hQEFgWAIpsnsF3MfRB03FZX5'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:09:54,192 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:09:54,193 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:09:54,194 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:09:54,195 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:09:54,195 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:09:54,196 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:09:54,747 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=0137dc25-d491-49ed-99ec-346dacce200c,id=3f1a983d-945c-4aaf-8858-0bd8fde79585; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=129a4c26-c3d1-48d3-bbc1-85d9866c6b4c; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=c28d4871-92ec-4ba8-beb7-0b730ab2e0d0; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=4ca15a19-287b-4daf-bfff-bb4b98250456
2025-06-12 13:09:54,912 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:09:59,165 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:09:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'3928'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'3932'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199367'), (b'x-ratelimit-reset-requests', b'13.766s'), (b'x-ratelimit-reset-tokens', b'189ms'), (b'x-request-id', b'req_cc3bbe6d827d7f3f1bd44561a1c32c06'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8e608e93cea3d-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:09:59,168 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:09:59,170 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:09:59,267 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:09:59,268 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:09:59,269 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:09:59,270 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:09:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '3928', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '3932', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199367', 'x-ratelimit-reset-requests': '13.766s', 'x-ratelimit-reset-tokens': '189ms', 'x-request-id': 'req_cc3bbe6d827d7f3f1bd44561a1c32c06', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8e608e93cea3d-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:09:59,272 - openai._base_client - DEBUG - request_id: req_cc3bbe6d827d7f3f1bd44561a1c32c06
2025-06-12 13:09:59,276 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:09:59,283 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 13:09:59,285 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:09:59,286 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:09:59,286 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 13:09:59,287 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 13:09:59,287 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 13:09:59,288 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:09:59,288 - src.agent - INFO - FINAL RESPONSE: 796 characters
2025-06-12 13:09:59,808 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=0137dc25-d491-49ed-99ec-346dacce200c,id=4ca15a19-287b-4daf-bfff-bb4b98250456; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=e75d6e03-a872-4056-bfd2-ba19fcb5357d; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=e75d6e03-a872-4056-bfd2-ba19fcb5357d; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=c28d4871-92ec-4ba8-beb7-0b730ab2e0d0; trace=0137dc25-d491-49ed-99ec-346dacce200c,id=0137dc25-d491-49ed-99ec-346dacce200c
2025-06-12 13:09:59,962 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:10:12,311 - src.agent - INFO - PROCESSING QUERY: 'what was the name of the guy we talked about just now?'
2025-06-12 13:10:12,313 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:10:12,316 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d0b92edb-fafe-4a40-a3dc-7cc58071fa76', 'json_data': {'messages': [{'content': 'what was the name of the guy we talked about just now?', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:10:12,317 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:10:12,318 - httpcore.connection - DEBUG - close.started
2025-06-12 13:10:12,318 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:10:12,318 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:10:12,351 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002025F8807D0>
2025-06-12 13:10:12,351 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000202340F9370> server_hostname='api.openai.com' timeout=None
2025-06-12 13:10:12,398 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002025F8B8640>
2025-06-12 13:10:12,399 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:10:12,400 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:10:12,401 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:10:12,401 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:10:12,402 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:10:12,866 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=0e4bfaa6-3981-4634-94ef-1c0c99437ba5,id=0e4bfaa6-3981-4634-94ef-1c0c99437ba5; trace=0e4bfaa6-3981-4634-94ef-1c0c99437ba5,id=26ec4c93-8129-4619-b48a-19af0b5d583b; trace=0e4bfaa6-3981-4634-94ef-1c0c99437ba5,id=3571060c-6b10-48b5-809f-7318be0706eb
2025-06-12 13:10:13,020 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:10:14,277 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:10:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1651'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1654'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199983'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_77a36b241df35fbfcb52b7a0e7b7c854'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8e67abfefea54-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:10:14,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:10:14,282 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:10:14,283 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:10:14,285 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:10:14,287 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:10:14,290 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:10:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '1651', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1654', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199983', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '4ms', 'x-request-id': 'req_77a36b241df35fbfcb52b7a0e7b7c854', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8e67abfefea54-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:10:14,292 - openai._base_client - DEBUG - request_id: req_77a36b241df35fbfcb52b7a0e7b7c854
2025-06-12 13:10:14,296 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:10:14,299 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:10:14,299 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:10:14,300 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:10:14,300 - src.agent - INFO - FINAL RESPONSE: 172 characters
2025-06-12 13:10:14,858 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=0e4bfaa6-3981-4634-94ef-1c0c99437ba5,id=3571060c-6b10-48b5-809f-7318be0706eb; trace=0e4bfaa6-3981-4634-94ef-1c0c99437ba5,id=c4158d43-8aa0-4487-8257-bbf7f4847bf1; trace=0e4bfaa6-3981-4634-94ef-1c0c99437ba5,id=c4158d43-8aa0-4487-8257-bbf7f4847bf1; trace=0e4bfaa6-3981-4634-94ef-1c0c99437ba5,id=26ec4c93-8129-4619-b48a-19af0b5d583b; trace=0e4bfaa6-3981-4634-94ef-1c0c99437ba5,id=0e4bfaa6-3981-4634-94ef-1c0c99437ba5
2025-06-12 13:10:15,016 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:10:23,636 - langsmith.client - DEBUG - Main thread is dead, stopping compression thread
2025-06-12 13:10:23,638 - langsmith.client - DEBUG - Compressed traces control thread is shutting down
2025-06-12 13:10:23,644 - langsmith.client - DEBUG - Main thread is dead, stopping tracing thread
2025-06-12 13:10:23,646 - langsmith.client - DEBUG - Tracing control thread is shutting down
2025-06-12 13:10:23,650 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 13:10:24,149 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 13:13:40,221 - src.utils - INFO - Loaded document: main-MSI_06-03 (1).pdf
2025-06-12 13:13:40,222 - src.utils - INFO - Total documents loaded: 70
2025-06-12 13:13:40,226 - src.utils - INFO - Split documents into 148 chunks
2025-06-12 13:13:43,577 - jax._src.path - DEBUG - etils.epath found. Using etils.epath for file I/O.
2025-06-12 13:13:43,967 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-06-12 13:13:43,968 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-06-12 13:13:43,969 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-06-12 13:13:44,388 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 13:13:44,719 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json HTTP/1.1" 200 0
2025-06-12 13:13:45,022 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 200 0
2025-06-12 13:13:45,171 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json HTTP/1.1" 200 0
2025-06-12 13:13:45,311 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json HTTP/1.1" 200 0
2025-06-12 13:13:45,447 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json HTTP/1.1" 404 0
2025-06-12 13:13:45,601 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 200 0
2025-06-12 13:13:45,903 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-06-12 13:13:46,057 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/revision/main HTTP/1.1" 200 6786
2025-06-12 13:13:46,204 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2 HTTP/1.1" 200 6786
2025-06-12 13:13:46,223 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-06-12 13:13:46,255 - chromadb.config - DEBUG - Starting component System
2025-06-12 13:13:46,256 - chromadb.config - DEBUG - Starting component Posthog
2025-06-12 13:13:46,793 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): us.i.posthog.com:443
2025-06-12 13:13:47,219 - urllib3.connectionpool - DEBUG - https://us.i.posthog.com:443 "POST /batch/ HTTP/1.1" 200 15
2025-06-12 13:13:49,021 - src.tools - INFO - Vector store initialized successfully
2025-06-12 13:13:49,041 - src.tools - INFO - Database connection established
2025-06-12 13:13:49,041 - src.tools - INFO - All tools initialized successfully
2025-06-12 13:13:49,042 - src.tools - INFO - Web search tool created successfully
2025-06-12 13:13:49,042 - src.tools - INFO - Web search tool available
2025-06-12 13:13:49,042 - src.tools - INFO - Document retrieval tool available
2025-06-12 13:13:49,042 - src.tools - INFO - SQL tool available
2025-06-12 13:13:49,043 - src.tools - INFO - Total available tools: 3
2025-06-12 13:13:49,049 - src.agent - INFO - AI Agent initialized successfully
2025-06-12 13:14:11,973 - src.agent - INFO - PROCESSING QUERY: 'search on the internet the last album published by tool'
2025-06-12 13:14:11,981 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443
2025-06-12 13:14:12,215 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "GET /info HTTP/1.1" 200 748
2025-06-12 13:14:12,267 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:14:12,270 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-04fc00ae-73f3-4ce8-964e-c91403ffd5c2', 'json_data': {'messages': [{'content': 'search on the internet the last album published by tool', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:14:12,271 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:14:12,271 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:14:12,302 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E52E60D70>
2025-06-12 13:14:12,302 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013E276492E0> server_hostname='api.openai.com' timeout=None
2025-06-12 13:14:12,350 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E52EF1D10>
2025-06-12 13:14:12,353 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:14:12,356 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:14:12,357 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:14:12,359 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:14:12,360 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:14:12,810 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=74e3a317-7da4-4b10-88dc-eb256213b760; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=5b611ff3-18a0-461b-8240-ec312f81c8e8; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=9ca88d3a-896c-4613-8c06-1ac25d5818a0
2025-06-12 13:14:12,978 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:12,995 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:14:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'407'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'409'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199983'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'4ms'), (b'x-request-id', b'req_f0adf57038700aa928e571a1ed1052d6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cxzL_Mb6yqEIxP1rjiAqX1IuO_aLEXaEQAiTAKLInu4-1749726852-1.0.1.1-dB_u75IOO69d59ZXrdk0q9pO2kLXjaM5avYMJo1FTBNpkt5K8EV5IeUaZOix8Zu6jpmTesOUPYOIvs_wSqt_bEmBQgFrvv945GK7baBmpa8; path=/; expires=Thu, 12-Jun-25 11:44:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.ojf4A2KloVqWlcIxQtPEEXonkJJIrx3z.rLofpGs7s-1749726852203-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8ec566a826130-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:14:13,004 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:14:13,006 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:14:13,008 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:14:13,010 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:14:13,011 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:14:13,014 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 12 Jun 2025 11:14:12 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'politecnico-di-torino-bgszq8'), ('openai-processing-ms', '407'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '409'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199983'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '4ms'), ('x-request-id', 'req_f0adf57038700aa928e571a1ed1052d6'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=cxzL_Mb6yqEIxP1rjiAqX1IuO_aLEXaEQAiTAKLInu4-1749726852-1.0.1.1-dB_u75IOO69d59ZXrdk0q9pO2kLXjaM5avYMJo1FTBNpkt5K8EV5IeUaZOix8Zu6jpmTesOUPYOIvs_wSqt_bEmBQgFrvv945GK7baBmpa8; path=/; expires=Thu, 12-Jun-25 11:44:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.ojf4A2KloVqWlcIxQtPEEXonkJJIrx3z.rLofpGs7s-1749726852203-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '94e8ec566a826130-FCO'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-06-12 13:14:13,017 - openai._base_client - DEBUG - request_id: req_f0adf57038700aa928e571a1ed1052d6
2025-06-12 13:14:13,083 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:14:13,096 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.tavily.com:443
2025-06-12 13:14:13,637 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=9ca88d3a-896c-4613-8c06-1ac25d5818a0; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=d04ed02d-60ab-487c-b5cb-c8f524e5a3da; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=d04ed02d-60ab-487c-b5cb-c8f524e5a3da; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=5b611ff3-18a0-461b-8240-ec312f81c8e8; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=14bf333c-2e49-456a-8d59-f5c452c383e9; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=7f28cdab-3304-4e9b-bad8-8ed3f84f7d91
2025-06-12 13:14:13,803 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:17,425 - urllib3.connectionpool - DEBUG - https://api.tavily.com:443 "POST /search HTTP/1.1" 200 792
2025-06-12 13:14:17,438 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:14:17,458 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-71cded55-7960-4ba4-adf2-87ebe043a052', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search on the internet the last album published by tool', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_0QT8mS7oyypWrEg7GKvF6jLq', 'function': {'name': 'tavily_search_results_json', 'arguments': '{"query": "last album published by Tool"}'}}]}, {'content': '[{"title": "Tool Albums and Discography - Genius", "url": "https://genius.com/artists/Tool/albums", "content": "All Albums by Tool · Fear Inoculum. August 30, 2019 · 10,000 Days. May 2, 2006 · Lateralus. May 15, 2001 · Salival. December 12, 2000 · Ænima. September 17, 1996", "score": 0.80625874}, {"title": "Tool Planning Three Months in Studio to \'Organize Ideas\' for New LP", "url": "https://www.billboard.com/music/music-news/tool-planning-three-months-studio-time-organize-ideas-new-album-1235904142/", "content": "Tool last released a studio album in 2019, with \'Fear Inoculum\' arriving after a 13-year wait.", "score": 0.80442166}]', 'role': 'tool', 'tool_call_id': 'call_0QT8mS7oyypWrEg7GKvF6jLq'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:14:17,467 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:14:17,470 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:14:17,473 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:14:17,475 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:14:17,477 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:14:17,478 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:14:17,989 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=7f28cdab-3304-4e9b-bad8-8ed3f84f7d91; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=14bf333c-2e49-456a-8d59-f5c452c383e9; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=b4735b91-afe4-4aa0-a9db-08679c06bd65; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=9d984637-603f-4b1e-88ec-fc3d577dbf1b
2025-06-12 13:14:18,148 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:18,751 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:14:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1052'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1056'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199611'), (b'x-ratelimit-reset-requests', b'12.157s'), (b'x-ratelimit-reset-tokens', b'116ms'), (b'x-request-id', b'req_16ecd5aa97c86a20809c757327023864'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8ec768b336130-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:14:18,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:14:18,753 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:14:18,754 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:14:18,755 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:14:18,756 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:14:18,757 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:14:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '1052', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1056', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199611', 'x-ratelimit-reset-requests': '12.157s', 'x-ratelimit-reset-tokens': '116ms', 'x-request-id': 'req_16ecd5aa97c86a20809c757327023864', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8ec768b336130-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:14:18,758 - openai._base_client - DEBUG - request_id: req_16ecd5aa97c86a20809c757327023864
2025-06-12 13:14:18,762 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:14:18,766 - src.agent - INFO - GRAPH EXECUTION: 3 events processed
2025-06-12 13:14:18,767 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:14:18,767 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:14:18,768 - src.agent - DEBUG - Event 2: ['tools']
2025-06-12 13:14:18,768 - src.agent - INFO - TOOLS NODE EXECUTED: Tools were actually called!
2025-06-12 13:14:18,769 - src.agent - DEBUG - Event 3: ['chatbot']
2025-06-12 13:14:18,769 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:14:18,769 - src.agent - INFO - FINAL RESPONSE: 204 characters
2025-06-12 13:14:19,303 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=9d984637-603f-4b1e-88ec-fc3d577dbf1b; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=107b41de-c661-4ea6-a96c-a6936ffe1009; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=107b41de-c661-4ea6-a96c-a6936ffe1009; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=b4735b91-afe4-4aa0-a9db-08679c06bd65; trace=74e3a317-7da4-4b10-88dc-eb256213b760,id=74e3a317-7da4-4b10-88dc-eb256213b760
2025-06-12 13:14:19,460 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:31,386 - src.agent - INFO - PROCESSING QUERY: 'what was the name of the band again?'
2025-06-12 13:14:31,386 - src.agent - INFO - ADDED CONVERSATION CONTEXT to query
2025-06-12 13:14:31,388 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:14:31,392 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-935dcb9a-c47e-46be-8030-a0d9ad453201', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search on the internet the last album published by tool', 'role': 'user'}, {'content': 'The last album published by Tool is "Fear Inoculum," which was released on August 30, 2019. You can find more details about their albums on platforms like [Genius](https://genius.com/artists/Tool/albums).', 'role': 'assistant'}, {'content': 'what was the name of the band again?', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:14:31,394 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:14:31,394 - httpcore.connection - DEBUG - close.started
2025-06-12 13:14:31,395 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:14:31,395 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:14:31,425 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E52E20550>
2025-06-12 13:14:31,425 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013E276492E0> server_hostname='api.openai.com' timeout=None
2025-06-12 13:14:31,474 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E52E58510>
2025-06-12 13:14:31,474 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:14:31,475 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:14:31,475 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:14:31,476 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:14:31,478 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:14:31,938 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7,id=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7; trace=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7,id=86722ff5-4309-4f95-860c-6f7c267557b3; trace=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7,id=ed05b676-9cf0-482b-b9a3-e5685637dcb0
2025-06-12 13:14:32,102 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:32,333 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:14:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'505'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'509'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199712'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'86ms'), (b'x-request-id', b'req_66ea43179f5a198b135f74675f5c913f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8eccdea85ea49-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:14:32,334 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:14:32,334 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:14:32,334 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:14:32,335 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:14:32,335 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:14:32,335 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:14:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '505', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '509', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199712', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '86ms', 'x-request-id': 'req_66ea43179f5a198b135f74675f5c913f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8eccdea85ea49-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:14:32,335 - openai._base_client - DEBUG - request_id: req_66ea43179f5a198b135f74675f5c913f
2025-06-12 13:14:32,341 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:14:32,343 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:14:32,343 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:14:32,343 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:14:32,343 - src.agent - INFO - FINAL RESPONSE: 29 characters
2025-06-12 13:14:32,868 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7,id=ed05b676-9cf0-482b-b9a3-e5685637dcb0; trace=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7,id=b8ab0593-76f1-440a-86f0-b8a62af91146; trace=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7,id=b8ab0593-76f1-440a-86f0-b8a62af91146; trace=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7,id=86722ff5-4309-4f95-860c-6f7c267557b3; trace=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7,id=98d721a0-4ba8-4744-b4c6-1ecfaa8f7ef7
2025-06-12 13:14:33,026 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:41,509 - src.agent - INFO - PROCESSING QUERY: 'what was the name of the band'
2025-06-12 13:14:41,510 - src.agent - INFO - ADDED CONVERSATION CONTEXT to query
2025-06-12 13:14:41,512 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:14:41,516 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f037bee7-8fd7-498c-bbb0-46e7bdd9e73c', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search on the internet the last album published by tool', 'role': 'user'}, {'content': 'The last album published by Tool is "Fear Inoculum," which was released on August 30, 2019. You can find more details about their albums on platforms like [Genius](https://genius.com/artists/Tool/albums).', 'role': 'assistant'}, {'content': 'what was the name of the band again?', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'what was the name of the band', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:14:41,517 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:14:41,518 - httpcore.connection - DEBUG - close.started
2025-06-12 13:14:41,518 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:14:41,519 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:14:41,544 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E52E595B0>
2025-06-12 13:14:41,544 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013E276492E0> server_hostname='api.openai.com' timeout=None
2025-06-12 13:14:41,584 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E52E28290>
2025-06-12 13:14:41,584 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:14:41,585 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:14:41,585 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:14:41,586 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:14:41,586 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:14:42,052 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7,id=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7; trace=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7,id=309ab7a2-5f47-4c20-b668-e402b01f6a89; trace=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7,id=fd1f3035-eabf-4718-a8f0-386c5dcdeb01
2025-06-12 13:14:42,205 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:42,337 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:14:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'532'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'537'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199695'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'91ms'), (b'x-request-id', b'req_385c43d6673825b4200c92f5cbc59228'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8ed0d1d35ea38-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:14:42,340 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:14:42,341 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:14:42,343 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:14:42,344 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:14:42,346 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:14:42,347 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:14:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '532', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '537', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199695', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '91ms', 'x-request-id': 'req_385c43d6673825b4200c92f5cbc59228', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8ed0d1d35ea38-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:14:42,349 - openai._base_client - DEBUG - request_id: req_385c43d6673825b4200c92f5cbc59228
2025-06-12 13:14:42,373 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:14:42,380 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:14:42,380 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:14:42,381 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:14:42,381 - src.agent - INFO - FINAL RESPONSE: 29 characters
2025-06-12 13:14:42,916 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7,id=fd1f3035-eabf-4718-a8f0-386c5dcdeb01; trace=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7,id=995adc7b-79c3-4fff-bd50-ff502e58ab9b; trace=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7,id=995adc7b-79c3-4fff-bd50-ff502e58ab9b; trace=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7,id=309ab7a2-5f47-4c20-b668-e402b01f6a89; trace=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7,id=abcdda2c-117f-4fda-ba6e-ec36f96c5cf7
2025-06-12 13:14:43,074 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:46,680 - src.agent - INFO - PROCESSING QUERY: 'are you sure?'
2025-06-12 13:14:46,683 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:14:46,689 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-001e9327-0214-4dae-8825-0cbab20b410c', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search on the internet the last album published by tool', 'role': 'user'}, {'content': 'The last album published by Tool is "Fear Inoculum," which was released on August 30, 2019. You can find more details about their albums on platforms like [Genius](https://genius.com/artists/Tool/albums).', 'role': 'assistant'}, {'content': 'what was the name of the band again?', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'what was the name of the band', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'are you sure?', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:14:46,690 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:14:46,691 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:14:46,691 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:14:46,691 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:14:46,692 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:14:46,692 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:14:47,241 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc,id=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc; trace=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc,id=c1ac64c3-91e4-4dc5-b25c-b292baf193f8; trace=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc,id=ae033cab-fb9d-4ca6-8614-022808f70c07
2025-06-12 13:14:47,402 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:14:47,438 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:14:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'510'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'512'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199682'), (b'x-ratelimit-reset-requests', b'12.166s'), (b'x-ratelimit-reset-tokens', b'95ms'), (b'x-request-id', b'req_ad55a2f13401442f47abaaaa6c07f809'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8ed2cf87dea38-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:14:47,440 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:14:47,442 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:14:47,444 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:14:47,445 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:14:47,447 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:14:47,448 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:14:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '510', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '512', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199682', 'x-ratelimit-reset-requests': '12.166s', 'x-ratelimit-reset-tokens': '95ms', 'x-request-id': 'req_ad55a2f13401442f47abaaaa6c07f809', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8ed2cf87dea38-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:14:47,449 - openai._base_client - DEBUG - request_id: req_ad55a2f13401442f47abaaaa6c07f809
2025-06-12 13:14:47,466 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:14:47,469 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:14:47,469 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:14:47,470 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:14:47,470 - src.agent - INFO - FINAL RESPONSE: 46 characters
2025-06-12 13:14:47,987 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc,id=ae033cab-fb9d-4ca6-8614-022808f70c07; trace=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc,id=e881c31f-206a-41d3-806d-a5bee38c3485; trace=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc,id=e881c31f-206a-41d3-806d-a5bee38c3485; trace=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc,id=c1ac64c3-91e4-4dc5-b25c-b292baf193f8; trace=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc,id=1d0c12c4-6f4b-4952-a64d-877ddec6e7cc
2025-06-12 13:14:48,143 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:21:25,893 - src.agent - INFO - PROCESSING QUERY: 'what did we talk about'
2025-06-12 13:21:25,897 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:21:25,900 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-45e15c0b-3af1-4ca0-bf5a-f5cdab3c1553', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search on the internet the last album published by tool', 'role': 'user'}, {'content': 'The last album published by Tool is "Fear Inoculum," which was released on August 30, 2019. You can find more details about their albums on platforms like [Genius](https://genius.com/artists/Tool/albums).', 'role': 'assistant'}, {'content': 'what was the name of the band again?', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'what was the name of the band', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'are you sure?', 'role': 'user'}, {'content': 'Yes, I am sure. The band we discussed is Tool.', 'role': 'assistant'}, {'content': 'what did we talk about', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:21:25,901 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:21:25,902 - httpcore.connection - DEBUG - close.started
2025-06-12 13:21:25,902 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:21:25,902 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:21:25,993 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E51CB16A0>
2025-06-12 13:21:25,993 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013E276492E0> server_hostname='api.openai.com' timeout=None
2025-06-12 13:21:26,052 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E51CB17B0>
2025-06-12 13:21:26,052 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:21:26,053 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:21:26,054 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:21:26,054 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:21:26,055 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:21:26,425 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=4205a1b7-bfdb-40c3-88ee-8142b1eecca6,id=4205a1b7-bfdb-40c3-88ee-8142b1eecca6; trace=4205a1b7-bfdb-40c3-88ee-8142b1eecca6,id=dedefa23-af87-4ae2-bcda-b0312cc36e7d; trace=4205a1b7-bfdb-40c3-88ee-8142b1eecca6,id=31152386-a00e-4b1d-bc24-b57dd298db4b
2025-06-12 13:21:26,600 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:21:27,037 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:21:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'762'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'766'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199663'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'100ms'), (b'x-request-id', b'req_7f2975b0345efacef2d9dd601f1afac6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8f6ecfc5c77fa-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:21:27,038 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:21:27,038 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:21:27,038 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:21:27,039 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:21:27,039 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:21:27,039 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:21:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '762', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '766', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199663', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '100ms', 'x-request-id': 'req_7f2975b0345efacef2d9dd601f1afac6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8f6ecfc5c77fa-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:21:27,039 - openai._base_client - DEBUG - request_id: req_7f2975b0345efacef2d9dd601f1afac6
2025-06-12 13:21:27,046 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:21:27,048 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:21:27,048 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:21:27,048 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:21:27,048 - src.agent - INFO - FINAL RESPONSE: 116 characters
2025-06-12 13:21:27,607 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=4205a1b7-bfdb-40c3-88ee-8142b1eecca6,id=31152386-a00e-4b1d-bc24-b57dd298db4b; trace=4205a1b7-bfdb-40c3-88ee-8142b1eecca6,id=5a77cc16-be48-4c45-bc8c-866799f4b41d; trace=4205a1b7-bfdb-40c3-88ee-8142b1eecca6,id=5a77cc16-be48-4c45-bc8c-866799f4b41d; trace=4205a1b7-bfdb-40c3-88ee-8142b1eecca6,id=dedefa23-af87-4ae2-bcda-b0312cc36e7d; trace=4205a1b7-bfdb-40c3-88ee-8142b1eecca6,id=4205a1b7-bfdb-40c3-88ee-8142b1eecca6
2025-06-12 13:21:27,768 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:21:31,707 - src.agent - INFO - PROCESSING QUERY: 'ok'
2025-06-12 13:21:31,709 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:21:31,715 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-b93eb309-6e6d-4ba2-a7bc-a29d5cb3ff73', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search on the internet the last album published by tool', 'role': 'user'}, {'content': 'The last album published by Tool is "Fear Inoculum," which was released on August 30, 2019. You can find more details about their albums on platforms like [Genius](https://genius.com/artists/Tool/albums).', 'role': 'assistant'}, {'content': 'what was the name of the band again?', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'what was the name of the band', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'are you sure?', 'role': 'user'}, {'content': 'Yes, I am sure. The band we discussed is Tool.', 'role': 'assistant'}, {'content': 'what did we talk about', 'role': 'user'}, {'content': 'We talked about the band Tool, specifically their last album, which is "Fear Inoculum," released on August 30, 2019.', 'role': 'assistant'}, {'content': 'ok', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:21:31,717 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:21:31,718 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:21:31,718 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:21:31,718 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:21:31,719 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:21:31,719 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:21:32,271 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=24bff0e7-1372-4329-8b2b-3e43451d47ea,id=24bff0e7-1372-4329-8b2b-3e43451d47ea; trace=24bff0e7-1372-4329-8b2b-3e43451d47ea,id=8a1a8a0b-aa2b-43d9-b40b-c446374fa5cc; trace=24bff0e7-1372-4329-8b2b-3e43451d47ea,id=bc0bd483-3564-4287-bd4c-71e1dea62bc6
2025-06-12 13:21:32,426 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:21:32,605 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:21:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'656'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'668'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199632'), (b'x-ratelimit-reset-requests', b'11.612s'), (b'x-ratelimit-reset-tokens', b'110ms'), (b'x-request-id', b'req_71094b8006a6f9ed2a68ed92f64fda8b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8f71068a577fa-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:21:32,608 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:21:32,610 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:21:32,618 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:21:32,620 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:21:32,621 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:21:32,622 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:21:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '656', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '668', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199632', 'x-ratelimit-reset-requests': '11.612s', 'x-ratelimit-reset-tokens': '110ms', 'x-request-id': 'req_71094b8006a6f9ed2a68ed92f64fda8b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8f71068a577fa-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:21:32,624 - openai._base_client - DEBUG - request_id: req_71094b8006a6f9ed2a68ed92f64fda8b
2025-06-12 13:21:32,652 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:21:32,655 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:21:32,655 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:21:32,656 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:21:32,657 - src.agent - INFO - FINAL RESPONSE: 77 characters
2025-06-12 13:21:33,200 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=24bff0e7-1372-4329-8b2b-3e43451d47ea,id=bc0bd483-3564-4287-bd4c-71e1dea62bc6; trace=24bff0e7-1372-4329-8b2b-3e43451d47ea,id=8764a053-f067-4014-843d-05d31f07ab56; trace=24bff0e7-1372-4329-8b2b-3e43451d47ea,id=8764a053-f067-4014-843d-05d31f07ab56; trace=24bff0e7-1372-4329-8b2b-3e43451d47ea,id=8a1a8a0b-aa2b-43d9-b40b-c446374fa5cc; trace=24bff0e7-1372-4329-8b2b-3e43451d47ea,id=24bff0e7-1372-4329-8b2b-3e43451d47ea
2025-06-12 13:21:33,353 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:21:37,226 - src.agent - INFO - PROCESSING QUERY: 'no thanks'
2025-06-12 13:21:37,229 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:21:37,235 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-34f51c0a-6858-4c4b-9111-9510ae33db37', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search on the internet the last album published by tool', 'role': 'user'}, {'content': 'The last album published by Tool is "Fear Inoculum," which was released on August 30, 2019. You can find more details about their albums on platforms like [Genius](https://genius.com/artists/Tool/albums).', 'role': 'assistant'}, {'content': 'what was the name of the band again?', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'what was the name of the band', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'are you sure?', 'role': 'user'}, {'content': 'Yes, I am sure. The band we discussed is Tool.', 'role': 'assistant'}, {'content': 'what did we talk about', 'role': 'user'}, {'content': 'We talked about the band Tool, specifically their last album, which is "Fear Inoculum," released on August 30, 2019.', 'role': 'assistant'}, {'content': 'ok', 'role': 'user'}, {'content': 'If you have any more questions or need further information, feel free to ask!', 'role': 'assistant'}, {'content': 'no thanks', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:21:37,236 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:21:37,236 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:21:37,237 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:21:37,237 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:21:37,238 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:21:37,238 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:21:37,781 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=2ff21ffb-8b72-4e2e-816c-4df07a7cb307,id=2ff21ffb-8b72-4e2e-816c-4df07a7cb307; trace=2ff21ffb-8b72-4e2e-816c-4df07a7cb307,id=591d3431-8328-4a23-9378-a1418fbdc2d0; trace=2ff21ffb-8b72-4e2e-816c-4df07a7cb307,id=b90ffbf0-cd68-44c8-9d74-5b52eac5ef36
2025-06-12 13:21:37,948 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:21:38,597 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:21:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'907'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'914'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199608'), (b'x-ratelimit-reset-requests', b'14.522s'), (b'x-ratelimit-reset-tokens', b'117ms'), (b'x-request-id', b'req_4f9bb0955794898bb5c25846dd7c5fac'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8f732ec4477fa-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:21:38,601 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:21:38,603 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:21:38,605 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:21:38,605 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:21:38,606 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:21:38,607 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:21:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '907', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '914', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '199608', 'x-ratelimit-reset-requests': '14.522s', 'x-ratelimit-reset-tokens': '117ms', 'x-request-id': 'req_4f9bb0955794898bb5c25846dd7c5fac', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8f732ec4477fa-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:21:38,608 - openai._base_client - DEBUG - request_id: req_4f9bb0955794898bb5c25846dd7c5fac
2025-06-12 13:21:38,610 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:21:38,618 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:21:38,619 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:21:38,619 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:21:38,619 - src.agent - INFO - FINAL RESPONSE: 99 characters
2025-06-12 13:21:39,160 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=2ff21ffb-8b72-4e2e-816c-4df07a7cb307,id=b90ffbf0-cd68-44c8-9d74-5b52eac5ef36; trace=2ff21ffb-8b72-4e2e-816c-4df07a7cb307,id=dddeb325-acb2-4fe6-a9c5-a6bd0f331b98; trace=2ff21ffb-8b72-4e2e-816c-4df07a7cb307,id=dddeb325-acb2-4fe6-a9c5-a6bd0f331b98; trace=2ff21ffb-8b72-4e2e-816c-4df07a7cb307,id=591d3431-8328-4a23-9378-a1418fbdc2d0; trace=2ff21ffb-8b72-4e2e-816c-4df07a7cb307,id=2ff21ffb-8b72-4e2e-816c-4df07a7cb307
2025-06-12 13:21:39,315 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:21:54,054 - src.agent - INFO - PROCESSING QUERY: 'yeah actually I do. I forgot what we were talking about'
2025-06-12 13:21:54,056 - src.agent - INFO - CHATBOT NODE: Processing user message
2025-06-12 13:21:54,062 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-67e99d11-b7e7-4634-baee-7b344acbf685', 'json_data': {'messages': [{'content': 'You are a helpful AI assistant with access to web search, document retrieval, and SQL database tools.\n\nIMPORTANT: You have access to the full conversation history. When users refer to previous topics, people, or information mentioned earlier (using words like "he", "she", "that person", "what was his name", "again", etc.), you MUST use the conversation context to understand what they\'re referring to.\n\nDO NOT ask for clarification if the answer is clearly available in the conversation history. Instead, use the context to provide a direct answer.\n\nExamples:\n- If user asks "what was his name again?" and previously discussed "John Smith", answer "John Smith"\n- If user asks "that company I mentioned" and previously discussed "Google", refer to Google\n- Always prioritize conversation context over tool usage for reference questions', 'role': 'system'}, {'content': 'search on the internet the last album published by tool', 'role': 'user'}, {'content': 'The last album published by Tool is "Fear Inoculum," which was released on August 30, 2019. You can find more details about their albums on platforms like [Genius](https://genius.com/artists/Tool/albums).', 'role': 'assistant'}, {'content': 'what was the name of the band again?', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'what was the name of the band', 'role': 'user'}, {'content': 'The name of the band is Tool.', 'role': 'assistant'}, {'content': 'are you sure?', 'role': 'user'}, {'content': 'Yes, I am sure. The band we discussed is Tool.', 'role': 'assistant'}, {'content': 'what did we talk about', 'role': 'user'}, {'content': 'We talked about the band Tool, specifically their last album, which is "Fear Inoculum," released on August 30, 2019.', 'role': 'assistant'}, {'content': 'ok', 'role': 'user'}, {'content': 'If you have any more questions or need further information, feel free to ask!', 'role': 'assistant'}, {'content': 'no thanks', 'role': 'user'}, {'content': "You're welcome! If you ever have questions in the future, feel free to reach out. Have a great day!", 'role': 'assistant'}, {'content': 'yeah actually I do. I forgot what we were talking about', 'role': 'user'}], 'model': 'gpt-4o-mini', 'stream': False, 'tools': [{'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'retriever_tool', 'description': 'Tool to Retrieve Semantically Similar documents to answer User Questions related to FutureSmart AI', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'nl2sql_tool', 'description': 'Tool to Generate and Execute SQL Query to answer User Questions related to chinook DB', 'parameters': {'properties': {'question': {'type': 'string'}}, 'required': ['question'], 'type': 'object'}}}]}}
2025-06-12 13:21:54,063 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 13:21:54,064 - httpcore.connection - DEBUG - close.started
2025-06-12 13:21:54,064 - httpcore.connection - DEBUG - close.complete
2025-06-12 13:21:54,064 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 13:21:54,089 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E52E20750>
2025-06-12 13:21:54,090 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000013E276492E0> server_hostname='api.openai.com' timeout=None
2025-06-12 13:21:54,264 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000013E52E20850>
2025-06-12 13:21:54,266 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 13:21:54,268 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 13:21:54,268 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 13:21:54,270 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 13:21:54,271 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 13:21:54,616 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8,id=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8; trace=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8,id=91609a7d-3efa-4d5f-b5e9-7bf7ed3c2ae3; trace=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8,id=def7e4bc-466d-417f-a8df-0fc5a247a008
2025-06-12 13:21:54,771 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:21:55,912 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 12 Jun 2025 11:21:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'politecnico-di-torino-bgszq8'), (b'openai-processing-ms', b'1412'), (b'openai-version', b'2020-10-01'), (b'x-envoy-upstream-service-time', b'1419'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199567'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'129ms'), (b'x-request-id', b'req_36ae6751888cedcc4c96759bdf3baeff'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e8f79d5f10e1f2-FCO'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 13:21:55,915 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-06-12 13:21:55,916 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 13:21:56,015 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 13:21:56,017 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 13:21:56,018 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 13:21:56,020 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Thu, 12 Jun 2025 11:21:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'politecnico-di-torino-bgszq8', 'openai-processing-ms': '1412', 'openai-version': '2020-10-01', 'x-envoy-upstream-service-time': '1419', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '199567', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '129ms', 'x-request-id': 'req_36ae6751888cedcc4c96759bdf3baeff', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e8f79d5f10e1f2-FCO', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 13:21:56,022 - openai._base_client - DEBUG - request_id: req_36ae6751888cedcc4c96759bdf3baeff
2025-06-12 13:21:56,026 - src.agent - INFO - CHATBOT NODE: Response type: AIMessage
2025-06-12 13:21:56,034 - src.agent - INFO - GRAPH EXECUTION: 1 events processed
2025-06-12 13:21:56,038 - src.agent - DEBUG - Event 1: ['chatbot']
2025-06-12 13:21:56,039 - src.agent - INFO - CHATBOT NODE EXECUTED
2025-06-12 13:21:56,040 - src.agent - INFO - FINAL RESPONSE: 194 characters
2025-06-12 13:21:56,599 - langsmith.client - DEBUG - Sending compressed multipart request with context: trace=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8,id=def7e4bc-466d-417f-a8df-0fc5a247a008; trace=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8,id=d1c09105-77f8-48f5-a216-517d4f07ab0d; trace=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8,id=d1c09105-77f8-48f5-a216-517d4f07ab0d; trace=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8,id=91609a7d-3efa-4d5f-b5e9-7bf7ed3c2ae3; trace=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8,id=c506342d-64b3-4e8d-8e86-8d3a7d47f8c8
2025-06-12 13:21:56,755 - urllib3.connectionpool - DEBUG - https://api.smith.langchain.com:443 "POST /runs/multipart HTTP/1.1" 202 34
2025-06-12 13:22:01,865 - langsmith.client - DEBUG - Main thread is dead, stopping compression thread
2025-06-12 13:22:01,865 - langsmith.client - DEBUG - Main thread is dead, stopping tracing thread
2025-06-12 13:22:01,865 - langsmith.client - DEBUG - Compressed traces control thread is shutting down
2025-06-12 13:22:01,865 - langsmith.client - DEBUG - Tracing control thread is shutting down
2025-06-12 13:22:01,866 - langsmith.client - DEBUG - Closing Client.session
2025-06-12 13:22:02,058 - langsmith.client - DEBUG - Closing Client.session
